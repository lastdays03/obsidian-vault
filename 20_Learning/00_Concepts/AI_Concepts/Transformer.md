# Transformer

**Category**: #concept/dl/architecture
**Source**: [[31_DL_Attention_and_RAG]]

## 정의
**Attention 메커니즘**만으로 구성된 혁명적인 신경망 구조입니다.

## 핵심 특징
- RNN 없이 시퀀스 처리
- 병렬 처리 가능 (RNN보다 훨씬 빠름)
- 장거리 의존성 학습 우수

## 구조
- **Encoder**: 입력 시퀀스 이해
- **Decoder**: 출력 시퀀스 생성
- **Multi-Head Attention**: 여러 관점에서 정보 추출

## 영향
- BERT (Encoder만 사용)
- GPT (Decoder만 사용)
- 현대 NLP의 표준 아키텍처

## 관련 개념
- [[Attention Mechanism]]
- [[RAG]]
