---
tags:
  - knowledge/topic
Source: [[GitHub_Study_Python]]
---

# Pandas 라이브러리 완전 가이드

## 📖 정의 (Definition)
**Pandas**는 파이썬에서 데이터 분석과 조작을 위한 가장 강력한 라이브러리입니다. 엑셀과 유사한 2차원 테이블 형태의 DataFrame을 제공하여 대용량 데이터의 정제, 변환, 분석을 효율적으로 수행합니다.

---

## 목차

1. [Pandas 소개](#1-pandas-소개)
2. [Series (1차원 데이터)](#2-series-1차원-데이터)
3. [DataFrame (2차원 데이터)](#3-dataframe-2차원-데이터)
4. [데이터 읽기와 쓰기](#4-데이터-읽기와-쓰기)
5. [데이터 선택 및 인덱싱](#5-데이터-선택-및-인덱싱)
6. [데이터 필터링](#6-데이터-필터링)
7. [데이터 정렬](#7-데이터-정렬)
8. [결측치 처리](#8-결측치-처리)
9. [데이터 변형 및 추가](#9-데이터-변형-및-추가)
10. [그룹화 및 집계](#10-그룹화-및-집계)
11. [데이터 병합 및 조인](#11-데이터-병합-및-조인)
12. [문자열 처리](#12-문자열-처리)
13. [시계열 데이터 처리](#13-시계열-데이터-처리)
14. [통계 함수](#14-통계-함수)
15. [데이터 시각화](#15-데이터-시각화)
16. [실전 예제](#16-실전-예제)
17. [요약](#17-요약)

---

## 1. Pandas 소개

### 1.1 Pandas란?

**Pandas**는 파이썬에서 데이터 분석과 조작을 위한 강력한 라이브러리입니다. NumPy를 기반으로 하며, 표 형태의 데이터를 효율적으로 다룰 수 있게 해줍니다.

### 1.2 Pandas의 주요 특징

- **Series**: 1차원 레이블이 있는 배열
- **DataFrame**: 2차원 레이블이 있는 테이블 구조
- **데이터 입출력**: CSV, Excel, JSON, SQL 등 다양한 형식 지원
- **결측치 처리**: 누락된 데이터를 쉽게 처리
- **데이터 변형**: 그룹화, 피벗, 병합 등 다양한 데이터 조작
- **시계열 처리**: 날짜/시간 데이터 처리에 특화
- **성능**: 대용량 데이터를 효율적으로 처리

### 1.3 설치

```bash
pip install pandas
```

### 1.4 기본 임포트

```python
import pandas as pd
import numpy as np
```

---

## 2. Series (1차원 데이터)

### 2.1 Series 생성

**설명**: Series는 1차원 레이블이 있는 배열입니다. 인덱스를 통해 데이터에 접근할 수 있으며, 다양한 데이터 타입을 저장할 수 있습니다.

**사용 사례**:
- 시계열 데이터 (날짜별 온도, 주가 등)
- 단일 열 데이터 처리
- 데이터프레임의 한 열 추출
- 시간별/카테고리별 데이터 집계 결과

```python
import pandas as pd
import numpy as np

# 리스트에서 생성
s1 = pd.Series([1, 3, 5, 7, 9])
print(s1)
# 0    1
# 1    3
# 2    5
# 3    7
# 4    9
# dtype: int64

# 인덱스 지정
s2 = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])
print(s2)
# a    10
# b    20
# c    30
# d    40
# dtype: int64

# 딕셔너리에서 생성
s3 = pd.Series({'apple': 3, 'banana': 5, 'orange': 2})
print(s3)
# apple     3
# banana    5
# orange    2
# dtype: int64

# NumPy 배열에서 생성
s4 = pd.Series(np.array([1, 2, 3, 4, 5]))
print(s4)
```

### 2.2 Series 속성

**설명**: Series 객체의 기본 속성들을 확인하는 방법입니다. 데이터의 구조와 타입을 파악하는 데 사용됩니다.

**사용 사례**:
- 데이터 구조 확인
- 데이터 타입 검사
- 메모리 사용량 확인
- 데이터 크기 확인
- 디버깅 및 데이터 검증

```python
s = pd.Series([1, 2, 3, 4, 5], index=['a', 'b', 'c', 'd', 'e'])

print(s.values)      # [1 2 3 4 5] (NumPy 배열)
print(s.index)       # Index(['a', 'b', 'c', 'd', 'e'])
print(s.dtype)       # int64
print(s.size)        # 5
print(s.shape)       # (5,)
print(s.name)        # None (이름이 없으면)
```

### 2.3 Series 인덱싱

**설명**: Series에서 데이터를 선택하는 다양한 방법입니다. 라벨 인덱싱, 위치 인덱싱, 불리언 인덱싱을 지원합니다.

**사용 사례**:
- 특정 값 추출
- 조건에 맞는 데이터 선택
- 데이터 샘플링
- 부분 데이터 추출
- 데이터 필터링

```python
s = pd.Series([10, 20, 30, 40, 50], index=['a', 'b', 'c', 'd', 'e'])

# 라벨로 인덱싱
print(s['a'])        # 10
print(s[['a', 'c']]) # a    10, c    30

# 위치로 인덱싱
print(s[0])          # 10
print(s[0:3])        # a    10, b    20, c    30

# 불리언 인덱싱
print(s[s > 30])     # d    40, e    50
```

### 2.4 Series 연산

**설명**: Series 간 또는 Series와 스칼라 간의 산술 연산과 통계 함수를 수행합니다. 인덱스를 기준으로 자동 정렬되어 연산됩니다.

**사용 사례**:
- 데이터 변환 (스케일링, 계산)
- 통계 계산 (평균, 합계 등)
- 데이터 비교
- 수학적 연산
- 데이터 요약

```python
s1 = pd.Series([1, 2, 3, 4, 5])
s2 = pd.Series([10, 20, 30, 40, 50])

# 산술 연산
print(s1 + s2)       # 0    11, 1    22, 2    33, 3    44, 4    55
print(s1 * 2)        # 0     2, 1     4, 2     6, 3     8, 4    10

# 통계 함수
print(s1.sum())      # 15
print(s1.mean())     # 3.0
print(s1.max())      # 5
print(s1.min())      # 1
print(s1.std())      # 1.5811388300841898
```

---

## 3. DataFrame (2차원 데이터)

### 3.1 DataFrame 생성

**설명**: DataFrame은 2차원 레이블이 있는 테이블 구조입니다. 행과 열 모두에 인덱스가 있어 Excel 스프레드시트와 유사합니다.

**사용 사례**:
- CSV/Excel 파일 읽기
- 데이터베이스 쿼리 결과 저장
- 실험 데이터 정리 (여러 변수와 관측값)
- 데이터 분석 및 시각화
- 머신러닝 데이터셋 준비

```python
import pandas as pd
import numpy as np

# 딕셔너리에서 생성
data = {
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '나이': [25, 30, 28, 35],
    '직업': ['개발자', '디자이너', '개발자', '기획자']
}
df = pd.DataFrame(data)
print(df)
#     이름  나이    직업
# 0  홍길동  25  개발자
# 1  김철수  30  디자이너
# 2  이영희  28  개발자
# 3  박민수  35  기획자

# 리스트의 리스트에서 생성
data_list = [
    ['홍길동', 25, '개발자'],
    ['김철수', 30, '디자이너'],
    ['이영희', 28, '개발자']
]
df2 = pd.DataFrame(data_list, columns=['이름', '나이', '직업'])
print(df2)

# NumPy 배열에서 생성
arr = np.random.randn(4, 3)
df3 = pd.DataFrame(arr, columns=['A', 'B', 'C'])
print(df3)
```

### 3.2 DataFrame 속성

**설명**: DataFrame의 구조와 메타데이터를 확인하는 속성들입니다. 데이터의 형태, 크기, 타입 등을 파악하는 데 사용됩니다.

**사용 사례**:
- 데이터 구조 확인
- 데이터 크기 확인
- 열 이름 확인
- 데이터 타입 검사
- 데이터 요약 정보 확인

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희'],
    '나이': [25, 30, 28],
    '직업': ['개발자', '디자이너', '개발자']
})

print(df.shape)          # (3, 3) - (행, 열)
print(df.size)           # 9 - 총 원소 개수
print(df.ndim)           # 2 - 차원 수
print(df.index)          # RangeIndex(start=0, stop=3, step=1)
print(df.columns)        # Index(['이름', '나이', '직업'])
print(df.dtypes)         # 각 열의 데이터 타입
print(df.info())         # 데이터프레임 정보 요약
print(df.describe())     # 숫자형 열의 통계 요약
```

### 3.3 기본 정보 확인

**설명**: DataFrame의 데이터를 빠르게 확인하고 요약하는 메서드들입니다. 대용량 데이터를 다룰 때 유용합니다.

**사용 사례**:
- 데이터 미리보기
- 데이터 구조 파악
- 통계 요약 확인
- 데이터 타입 확인
- 데이터 품질 검사

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '나이': [25, 30, 28, 35],
    '급여': [3000, 4000, 3500, 5000]
})

# 처음 5개 행
print(df.head())
print(df.head(2))  # 처음 2개 행

# 마지막 5개 행
print(df.tail())
print(df.tail(2))  # 마지막 2개 행

# 데이터 타입
print(df.dtypes)

# 통계 요약 (숫자형 열만)
print(df.describe())

# 전체 정보
print(df.info())
```

---

### 3.4 Axis (축) 이해하기

**설명**: Pandas DataFrame은 2차원 데이터 구조이므로 행(Row)과 열(Column)이라는 두 가지 축을 가집니다. 많은 Pandas 함수들이 `axis` 매개변수를 통해 연산의 방향을 결정합니다.

**Axis 방향**:
- **axis=0 (index)**: 행(Row) 방향, 수직 아래로 이동 (↓)
- **axis=1 (columns)**: 열(Column) 방향, 수평 오른쪽으로 이동 (→)

**사용 사례**:
- 통계 연산 (합계, 평균 등)의 방향 지정
- 데이터 제거 (행 삭제 vs 열 삭제)
- 함수 적용 (`apply`) 방향 지정

```python
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6],
    'C': [7, 8, 9]
})

#      A  B  C
#  0   1  4  7
#  1   2  5  8
#  2   3  6  9
```

#### 3.4.1 Axis 방향과 연산의 결과 (헷갈리기 쉬운 점)

`axis` 매개변수는 **"어떤 축을 따라(along) 연산할 것인가"**를 지정합니다. 이로 인해 결과의 형태가 직관과 다르게 느껴질 수 있습니다.

| 구분 | axis=0 (행 방향) | axis=1 (열 방향) |
|------|------------------|------------------|
| **의미** | 인덱스(행)를 따라 이동 | 컬럼(열)을 따라 이동 |
| **통계 연산**<br>(sum, mean 등) | 행들을 압축하여 **열 단위 결과** 반환<br>(각 열의 합계) | 열들을 압축하여 **행 단위 결과** 반환<br>(각 행의 합계) |
| **구조 변경**<br>(drop 등) | **행(Row)**을 제거 | **열(Column)**을 제거 |

**예외/주의사항 (축 방향이 반대처럼 느껴지는 경우)**:
- **통계 함수 (`sum`, `mean` 등)**: `axis=0`을 지정하면 "행"을 따라 연산하므로, 결과적으로 "행"이 사라지고 "열"별 결과가 나옵니다. 이를 "행을 기준으로 계산한다"고 생각하면 반대로 느껴질 수 있습니다.
    - `df.sum(axis=0)`: 행을 따라 내려가며 더함 → **열의 합계**
    - `df.sum(axis=1)`: 열을 따라 옆으로 가며 더함 → **행의 합계**
- **구조 변경 함수 (`drop` 등)**: `axis=0`을 지정하면 "행" 축에 있는 라벨을 찾아서 제거합니다.
    - `df.drop(0, axis=0)`: 인덱스(행)에서 0을 찾아 제거 → **행 삭제**
    - `df.drop('A', axis=1)`: 컬럼(열)에서 'A'를 찾아 제거 → **열 삭제**

```python
# 1. 통계 연산 (Reduction)
print(df.sum(axis=0))
# A    6
# B   15
# C   24
# dtype: int64 (각 열의 합계, 행이 사라짐)

print(df.sum(axis=1))
# 0    12
# 1    15
# 2    18
# dtype: int64 (각 행의 합계, 열이 사라짐)

# 2. 구조 변경 (Drop)
print(df.drop(0, axis=0))  # 0번 행 삭제
#    A  B  C
# 1  2  5  8
# 2  3  6  9

print(df.drop('A', axis=1))  # 'A' 열 삭제
#    B  C
# 0  4  7
# 1  5  8
# 2  6  9
```

---

#### 3.4.2 `index`와 `columns` 키워드 사용 (가독성 향상)

`axis=0`이나 `axis=1` 대신 문자열 별칭(alias)이나 전용 키워드를 사용하면 코드의 의도를 더 명확하게 표현할 수 있습니다.

**1. 문자열 별칭 사용**:
- `axis=0` 대신 `axis='index'` 사용 가능
- `axis=1` 대신 `axis='columns'` 사용 가능

**2. 전용 키워드 사용 (`drop`, `rename` 등)**:
- 많은 함수들이 `axis` 매개변수 대신 `index`와 `columns` 매개변수를 직접 지원합니다.

```python
# 1. 문자열 별칭 사용
df.sum(axis='index')    # axis=0과 동일 (열의 합계)
df.sum(axis='columns')  # axis=1과 동일 (행의 합계)

# 2. 전용 키워드 사용 (권장)
# axis=0, axis=1을 사용하는 것보다 훨씬 직관적입니다.

# 행 삭제
df.drop(index=0)        # df.drop(0, axis=0)과 동일

# 열 삭제
df.drop(columns='A')    # df.drop('A', axis=1)과 동일

# 이름 변경 (rename)
df.rename(index={0: 'zero'}, columns={'A': 'Alpha'})
```

#### 3.4.3 인덱싱에서의 Axis 활용

인덱싱 메서드(`loc`, `iloc`)와 일부 선택 메서드들도 내부적으로 축 개념을 사용합니다.

**1. `loc` / `iloc`의 암묵적 축**:
- 첫 번째 인자는 **axis=0 (행)**을 선택합니다.
- 두 번째 인자는 **axis=1 (열)**을 선택합니다.

```python
# df.loc[행_선택, 열_선택]
df.loc[0, 'A']  # axis=0에서 0, axis=1에서 'A'
```

**2. `xs` (Cross-section) 메서드**:
- `axis`를 명시적으로 지정하여 특정 축의 단면을 잘라냅니다.
- 멀티인덱스에서 특정 레벨을 선택할 때 매우 유용합니다.

```python
# axis=0 (행)에서 인덱스가 0인 데이터 추출
df.xs(0, axis=0)

# axis=1 (열)에서 컬럼이 'A'인 데이터 추출
df.xs('A', axis=1)
```

**3. `take` 메서드**:
- 위치 기반(iloc 스타일)으로 데이터를 선택할 때 `axis`를 지정하여 사용할 수 있습니다.

```python
# axis=0 (행)의 0번째, 2번째 행 선택
df.take([0, 2], axis=0)

# axis=1 (열)의 0번째, 2번째 열 선택
df.take([0, 2], axis=1)
```

---

## 4. 데이터 읽기와 쓰기

### 4.1 CSV 파일 읽기/쓰기

**설명**: CSV(Comma-Separated Values) 파일은 가장 일반적인 데이터 교환 형식입니다. Pandas는 CSV 파일을 쉽게 읽고 쓸 수 있는 강력한 기능을 제공합니다.

**사용 사례**:
- 데이터 분석 프로젝트의 데이터 로드
- Excel에서 내보낸 데이터 처리
- 데이터 전처리 결과 저장
- 다른 시스템과의 데이터 교환
- 로그 파일 분석

```python
# CSV 파일 읽기
df = pd.read_csv('data.csv')
print(df)

# 옵션 지정
df = pd.read_csv('data.csv', 
                 encoding='utf-8',      # 인코딩
                 sep=',',               # 구분자
                 header=0,              # 헤더 행
                 index_col=0,           # 인덱스로 사용할 열
                 na_values=['NA', 'N/A'])  # 결측치로 처리할 값

# CSV 파일 쓰기
df.to_csv('output.csv', index=False, encoding='utf-8-sig')

# 옵션 지정
df.to_csv('output.csv',
          index=False,           # 인덱스 저장 안 함
          encoding='utf-8-sig',  # 한글 인코딩
          sep=',',               # 구분자
          na_rep='NA')           # 결측치 표시
```

#### 4.1.1 read_csv() 자주 사용하는 옵션

| 옵션 | 기본값 | 설명 | 예시 |
|------|--------|------|------|
| `filepath_or_buffer` | - | 파일 경로 또는 URL | `'data.csv'`, `'https://example.com/data.csv'` |
| `sep` | `','` | 구분자 (delimiter) | `sep='\t'` (탭), `sep=';'` (세미콜론) |
| `delimiter` | `None` | sep과 동일 (구분자) | `delimiter=','` |
| `header` | `0` | 헤더로 사용할 행 번호 | `header=0` (첫 행), `header=None` (헤더 없음) |
| `index_col` | `None` | 인덱스로 사용할 열 | `index_col=0` (첫 열), `index_col='이름'` |
| `names` | `None` | 열 이름 리스트 | `names=['A', 'B', 'C']` |
| `usecols` | `None` | 읽을 열 지정 | `usecols=[0, 1, 2]`, `usecols=['이름', '나이']` |
| `dtype` | `None` | 열의 데이터 타입 지정 | `dtype={'나이': int, '급여': float}` |
| `encoding` | `None` | 파일 인코딩 | `encoding='utf-8'`, `encoding='cp949'` (한글) |
| `skiprows` | `None` | 건너뛸 행 번호 | `skiprows=1` (첫 행 제외), `skiprows=[0, 2]` |
| `nrows` | `None` | 읽을 행 개수 | `nrows=100` (처음 100행만) |
| `na_values` | `None` | 결측치로 처리할 값 | `na_values=['NA', 'N/A', '']` |
| `keep_default_na` | `True` | 기본 결측치 값 유지 | `keep_default_na=False` |
| `skip_blank_lines` | `True` | 빈 줄 건너뛰기 | `skip_blank_lines=False` |
| `parse_dates` | `False` | 날짜로 변환할 열 | `parse_dates=['날짜']`, `parse_dates=True` |
| `date_parser` | `None` | 날짜 파싱 함수 | `date_parser=pd.to_datetime` |
| `thousands` | `None` | 천 단위 구분자 | `thousands=','` (1,000 → 1000) |
| `decimal` | `'.'` | 소수점 구분자 | `decimal=','` (유럽식) |
| `comment` | `None` | 주석 문자 | `comment='#'` (#로 시작하는 줄 무시) |
| `skipinitialspace` | `False` | 구분자 뒤 공백 제거 | `skipinitialspace=True` |
| `low_memory` | `True` | 메모리 효율적 읽기 | `low_memory=False` (타입 추론 정확) |
| `chunksize` | `None` | 청크 단위로 읽기 | `chunksize=1000` (1000행씩) |
| `engine` | `'c'` | 파싱 엔진 | `engine='python'` (C 엔진 실패 시) |

**자주 사용하는 조합 예시**:
```python
# 한글 파일 읽기
df = pd.read_csv('data.csv', encoding='utf-8-sig')

# 탭 구분 파일
df = pd.read_csv('data.tsv', sep='\t')

# 헤더 없이 읽고 열 이름 지정
df = pd.read_csv('data.csv', header=None, names=['이름', '나이', '직업'])

# 특정 열만 읽기
df = pd.read_csv('data.csv', usecols=['이름', '나이'])

# 날짜 열 자동 변환
df = pd.read_csv('data.csv', parse_dates=['날짜'])

# 대용량 파일 청크 단위로 읽기
for chunk in pd.read_csv('large_file.csv', chunksize=1000):
    process(chunk)
```

#### 4.1.2 to_csv() 자주 사용하는 옵션

| 옵션 | 기본값 | 설명 | 예시 |
|------|--------|------|------|
| `path_or_buf` | - | 파일 경로 또는 버퍼 | `'output.csv'` |
| `sep` | `','` | 구분자 | `sep='\t'` (탭) |
| `na_rep` | `''` | 결측치 표시 문자열 | `na_rep='NA'`, `na_rep='NULL'` |
| `float_format` | `None` | 실수 형식 | `float_format='%.2f'` (소수점 2자리) |
| `columns` | `None` | 저장할 열 지정 | `columns=['이름', '나이']` |
| `header` | `True` | 헤더 저장 여부 | `header=False` |
| `index` | `True` | 인덱스 저장 여부 | `index=False` (일반적으로 False) |
| `index_label` | `None` | 인덱스 열 이름 | `index_label='ID'` |
| `mode` | `'w'` | 파일 모드 | `mode='a'` (추가), `mode='w'` (덮어쓰기) |
| `encoding` | `None` | 파일 인코딩 | `encoding='utf-8-sig'` (Excel 호환) |
| `compression` | `None` | 압축 형식 | `compression='gzip'` |
| `quoting` | `0` | 인용 부호 처리 | `quoting=1` (모든 필드 인용) |
| `quotechar` | `'"'` | 인용 부호 문자 | `quotechar="'"` |
| `line_terminator` | `'\n'` | 줄 종료 문자 | `line_terminator='\r\n'` (Windows) |
| `date_format` | `None` | 날짜 형식 | `date_format='%Y-%m-%d'` |

**자주 사용하는 조합 예시**:
```python
# Excel에서 열 수 있도록 한글 인코딩
df.to_csv('output.csv', index=False, encoding='utf-8-sig')

# 탭 구분 파일로 저장
df.to_csv('output.tsv', sep='\t', index=False)

# 실수 소수점 2자리로 저장
df.to_csv('output.csv', float_format='%.2f', index=False)

# 특정 열만 저장
df.to_csv('output.csv', columns=['이름', '나이'], index=False)

# 압축 파일로 저장
df.to_csv('output.csv.gz', compression='gzip', index=False)
```

### 4.2 Excel 파일 읽기/쓰기

**설명**: Excel 파일(.xlsx, .xls)을 읽고 쓸 수 있습니다. 여러 시트를 다루거나 특정 시트만 선택할 수 있습니다.

**사용 사례**:
- Excel 데이터 분석
- 여러 시트 데이터 처리
- Excel 형식으로 결과 저장
- 비즈니스 데이터 처리
- 리포트 생성

```python
# Excel 파일 읽기
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')

# 여러 시트 읽기
excel_file = pd.ExcelFile('data.xlsx')
df1 = pd.read_excel(excel_file, 'Sheet1')
df2 = pd.read_excel(excel_file, 'Sheet2')

# Excel 파일 쓰기
df.to_excel('output.xlsx', index=False, sheet_name='Sheet1')

# 여러 시트 쓰기
with pd.ExcelWriter('output.xlsx') as writer:
    df1.to_excel(writer, sheet_name='Sheet1', index=False)
    df2.to_excel(writer, sheet_name='Sheet2', index=False)
```

#### 4.2.1 read_excel() 자주 사용하는 옵션

| 옵션 | 기본값 | 설명 | 예시 |
|------|--------|------|------|
| `io` | - | 파일 경로 또는 ExcelFile 객체 | `'data.xlsx'` |
| `sheet_name` | `0` | 읽을 시트 이름/번호 | `sheet_name=0`, `sheet_name='Sheet1'`, `sheet_name=None` (모든 시트) |
| `header` | `0` | 헤더로 사용할 행 번호 | `header=0`, `header=None` |
| `index_col` | `None` | 인덱스로 사용할 열 | `index_col=0` |
| `names` | `None` | 열 이름 리스트 | `names=['A', 'B', 'C']` |
| `usecols` | `None` | 읽을 열 지정 | `usecols='A:C'`, `usecols=[0, 1, 2]` |
| `dtype` | `None` | 열의 데이터 타입 | `dtype={'나이': int}` |
| `skiprows` | `None` | 건너뛸 행 번호 | `skiprows=1`, `skiprows=[0, 2]` |
| `nrows` | `None` | 읽을 행 개수 | `nrows=100` |
| `na_values` | `None` | 결측치로 처리할 값 | `na_values=['NA', '']` |
| `keep_default_na` | `True` | 기본 결측치 값 유지 | `keep_default_na=False` |
| `parse_dates` | `False` | 날짜로 변환할 열 | `parse_dates=['날짜']` |
| `engine` | `None` | 엔진 선택 | `engine='openpyxl'` (xlsx), `engine='xlrd'` (xls) |

**자주 사용하는 조합 예시**:
```python
# 특정 시트 읽기
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')

# 모든 시트 읽기
all_sheets = pd.read_excel('data.xlsx', sheet_name=None)  # 딕셔너리로 반환

# 특정 범위의 열만 읽기
df = pd.read_excel('data.xlsx', usecols='A:C')

# 헤더 없이 읽고 열 이름 지정
df = pd.read_excel('data.xlsx', header=None, names=['이름', '나이'])

# 첫 몇 행만 읽기
df = pd.read_excel('data.xlsx', nrows=100)
```

#### 4.2.2 to_excel() 자주 사용하는 옵션

| 옵션 | 기본값 | 설명 | 예시 |
|------|--------|------|------|
| `excel_writer` | - | 파일 경로 또는 ExcelWriter | `'output.xlsx'` |
| `sheet_name` | `'Sheet1'` | 시트 이름 | `sheet_name='데이터'` |
| `na_rep` | `''` | 결측치 표시 | `na_rep='NA'` |
| `float_format` | `None` | 실수 형식 | `float_format='%.2f'` |
| `columns` | `None` | 저장할 열 지정 | `columns=['이름', '나이']` |
| `header` | `True` | 헤더 저장 여부 | `header=False` |
| `index` | `True` | 인덱스 저장 여부 | `index=False` |
| `index_label` | `None` | 인덱스 열 이름 | `index_label='ID'` |
| `startrow` | `0` | 시작 행 위치 | `startrow=2` (3번째 행부터) |
| `startcol` | `0` | 시작 열 위치 | `startcol=1` (B열부터) |
| `engine` | `None` | 엔진 선택 | `engine='openpyxl'` |
| `freeze_panes` | `None` | 고정할 행/열 | `freeze_panes=(1, 0)` (첫 행 고정) |

**자주 사용하는 조합 예시**:
```python
# 기본 저장
df.to_excel('output.xlsx', index=False)

# 여러 시트에 저장
with pd.ExcelWriter('output.xlsx') as writer:
    df1.to_excel(writer, sheet_name='Sheet1', index=False)
    df2.to_excel(writer, sheet_name='Sheet2', index=False)

# 특정 위치에 저장
df.to_excel('output.xlsx', startrow=2, startcol=1, index=False)

# 첫 행 고정
df.to_excel('output.xlsx', freeze_panes=(1, 0), index=False)
```

### 4.3 JSON 파일 읽기/쓰기

**설명**: JSON 형식의 데이터를 읽고 쓸 수 있습니다. 웹 API와의 데이터 교환이나 설정 파일 처리에 유용합니다.

**사용 사례**:
- 웹 API 데이터 처리
- JSON 형식 데이터 로드
- 설정 파일 읽기/쓰기
- 데이터 교환 (다른 언어와)
- RESTful API 응답 처리

```python
# JSON 파일 읽기
df = pd.read_json('data.json')

# JSON 문자열에서 읽기
json_str = '{"이름": {"0": "홍길동", "1": "김철수"}, "나이": {"0": 25, "1": 30}}'
df = pd.read_json(json_str)

# JSON 파일 쓰기
df.to_json('output.json', orient='records', force_ascii=False)

# JSON 문자열로 변환
json_str = df.to_json(orient='records', force_ascii=False)
```

#### 4.3.1 read_json() 자주 사용하는 옵션

| 옵션 | 기본값 | 설명 | 예시 |
|------|--------|------|------|
| `path_or_buf` | - | 파일 경로, URL, JSON 문자열 | `'data.json'`, JSON 문자열 |
| `orient` | `None` | JSON 형식 (자동 감지) | `'records'`, `'index'`, `'columns'` |
| `typ` | `'frame'` | 반환 타입 | `'frame'` (DataFrame), `'series'` (Series) |
| `dtype` | `True` | 데이터 타입 추론 | `dtype=False` (문자열로 유지) |
| `convert_axes` | `True` | 축 변환 | `convert_axes=False` |
| `convert_dates` | `True` | 날짜 변환 | `convert_dates=['날짜']` |
| `keep_default_dates` | `True` | 기본 날짜 형식 유지 | `keep_default_dates=False` |
| `numpy` | `False` | NumPy 배열로 반환 | `numpy=True` |
| `precise_float` | `False` | 정밀한 실수 파싱 | `precise_float=True` |
| `date_unit` | `None` | 날짜 단위 | `date_unit='s'` (초) |
| `encoding` | `None` | 인코딩 | `encoding='utf-8'` |
| `lines` | `False` | JSONL 형식 (줄별 JSON) | `lines=True` |

**JSON orient 형식**:
- `'split'`: `{index: [...], columns: [...], data: [...]}`
- `'records'`: `[{col1: val1, col2: val2}, ...]` (가장 일반적)
- `'index'`: `{index: {col: val, ...}, ...}`
- `'columns'`: `{col: {index: val, ...}, ...}`
- `'values'`: `[[val1, val2, ...], ...]`

**자주 사용하는 조합 예시**:
```python
# 기본 JSON 파일 읽기
df = pd.read_json('data.json')

# JSONL 형식 (줄별 JSON) 읽기
df = pd.read_json('data.jsonl', lines=True)

# JSON 문자열에서 읽기
json_str = '[{"이름": "홍길동", "나이": 25}, {"이름": "김철수", "나이": 30}]'
df = pd.read_json(json_str)

# 특정 orient 형식 지정
df = pd.read_json('data.json', orient='records')
```

#### 4.3.2 to_json() 자주 사용하는 옵션

| 옵션 | 기본값 | 설명 | 예시 |
|------|--------|------|------|
| `path_or_buf` | `None` | 파일 경로 또는 버퍼 | `'output.json'`, `None` (문자열 반환) |
| `orient` | `'columns'` | JSON 형식 | `'records'`, `'index'`, `'split'` |
| `date_format` | `'epoch'` | 날짜 형식 | `'iso'`, `'epoch'` |
| `double_precision` | `10` | 실수 정밀도 | `double_precision=15` |
| `force_ascii` | `True` | ASCII만 사용 | `force_ascii=False` (한글 등 유니코드) |
| `date_unit` | `'ms'` | 날짜 단위 | `'s'` (초), `'ms'` (밀리초) |
| `default_handler` | `None` | 직렬화 불가 객체 처리 | `default_handler=str` |
| `lines` | `False` | JSONL 형식으로 저장 | `lines=True` |
| `compression` | `None` | 압축 형식 | `compression='gzip'` |
| `index` | `True` | 인덱스 포함 여부 | `index=False` |

**자주 사용하는 조합 예시**:
```python
# records 형식으로 저장 (가장 일반적)
df.to_json('output.json', orient='records', force_ascii=False)

# JSON 문자열로 변환
json_str = df.to_json(orient='records', force_ascii=False)

# JSONL 형식으로 저장 (줄별 JSON)
df.to_json('output.jsonl', orient='records', lines=True, force_ascii=False)

# 인덱스 제외하고 저장
df.to_json('output.json', orient='records', index=False, force_ascii=False)

# 날짜를 ISO 형식으로 저장
df.to_json('output.json', date_format='iso', force_ascii=False)
```

### 4.4 기타 형식

**설명**: HTML 테이블, SQL 데이터베이스 등 다양한 형식의 데이터를 읽고 쓸 수 있습니다. 웹 스크래핑이나 데이터베이스 연동에 사용됩니다.

**사용 사례**:
- 웹 스크래핑 (HTML 테이블)
- 데이터베이스 쿼리 결과 처리
- 데이터베이스에 데이터 저장
- 다양한 데이터 소스 통합
- 데이터 파이프라인 구축

```python
# HTML 테이블 읽기
df = pd.read_html('https://example.com/table.html')[0]

# SQL 데이터베이스 읽기
import sqlite3
conn = sqlite3.connect('database.db')
df = pd.read_sql_query("SELECT * FROM table_name", conn)

# SQL에 쓰기
df.to_sql('table_name', conn, if_exists='replace', index=False)
```

#### 4.4.1 read_sql() / read_sql_query() 자주 사용하는 옵션

| 옵션 | 기본값 | 설명 | 예시 |
|------|--------|------|------|
| `sql` | - | SQL 쿼리 문자열 | `"SELECT * FROM table"` |
| `con` | - | 데이터베이스 연결 객체 | `sqlite3.connect('db.db')` |
| `index_col` | `None` | 인덱스로 사용할 열 | `index_col='id'` |
| `coerce_float` | `True` | 숫자 문자열을 실수로 변환 | `coerce_float=False` |
| `params` | `None` | 쿼리 파라미터 | `params={'name': '홍길동'}` |
| `parse_dates` | `None` | 날짜로 변환할 열 | `parse_dates=['date']` |
| `chunksize` | `None` | 청크 단위로 읽기 | `chunksize=1000` |

**자주 사용하는 조합 예시**:
```python
import sqlite3

# SQLite 연결
conn = sqlite3.connect('database.db')

# 전체 테이블 읽기
df = pd.read_sql_query("SELECT * FROM users", conn)

# 조건부 쿼리
df = pd.read_sql_query("SELECT * FROM users WHERE age > 25", conn)

# 파라미터화된 쿼리 (SQL 인젝션 방지)
df = pd.read_sql_query("SELECT * FROM users WHERE name = ?", conn, params=['홍길동'])

# 특정 열만 인덱스로
df = pd.read_sql_query("SELECT * FROM users", conn, index_col='id')
```

#### 4.4.2 to_sql() 자주 사용하는 옵션

| 옵션 | 기본값 | 설명 | 예시 |
|------|--------|------|------|
| `name` | - | 테이블 이름 | `'users'` |
| `con` | - | 데이터베이스 연결 객체 | `sqlite3.connect('db.db')` |
| `schema` | `None` | 스키마 이름 | `schema='public'` |
| `if_exists` | `'fail'` | 테이블 존재 시 동작 | `'fail'`, `'replace'`, `'append'` |
| `index` | `True` | 인덱스 저장 여부 | `index=False` |
| `index_label` | `None` | 인덱스 열 이름 | `index_label='id'` |
| `chunksize` | `None` | 청크 단위로 쓰기 | `chunksize=1000` |
| `dtype` | `None` | 열의 데이터 타입 | `dtype={'age': Integer}` |
| `method` | `None` | 삽입 방법 | `method='multi'` (빠른 삽입) |

**자주 사용하는 조합 예시**:
```python
import sqlite3

conn = sqlite3.connect('database.db')

# 테이블 생성 및 저장
df.to_sql('users', conn, if_exists='replace', index=False)

# 기존 테이블에 추가
df.to_sql('users', conn, if_exists='append', index=False)

# 대용량 데이터 청크 단위로 저장
df.to_sql('users', conn, if_exists='replace', index=False, chunksize=1000)

# 인덱스를 ID 열로 저장
df.to_sql('users', conn, if_exists='replace', index=True, index_label='id')
```

#### 4.4.3 read_html() 자주 사용하는 옵션

| 옵션 | 기본값 | 설명 | 예시 |
|------|--------|------|------|
| `io` | - | URL, 파일 경로, HTML 문자열 | `'https://example.com'` |
| `match` | `None` | 매칭할 테이블 패턴 | `match='table'` |
| `flavor` | `None` | 파서 종류 | `'html5lib'`, `'lxml'` |
| `header` | `None` | 헤더로 사용할 행 | `header=0` |
| `index_col` | `None` | 인덱스로 사용할 열 | `index_col=0` |
| `skiprows` | `None` | 건너뛸 행 | `skiprows=1` |
| `attrs` | `None` | 테이블 속성 필터 | `attrs={'id': 'table1'}` |
| `parse_dates` | `False` | 날짜로 변환할 열 | `parse_dates=['date']` |

**자주 사용하는 조합 예시**:
```python
# 웹 페이지의 모든 테이블 읽기
tables = pd.read_html('https://example.com/table.html')
df = tables[0]  # 첫 번째 테이블

# 특정 ID를 가진 테이블만 읽기
df = pd.read_html('https://example.com', attrs={'id': 'data-table'})[0]

# 특정 클래스를 가진 테이블 읽기
df = pd.read_html('https://example.com', attrs={'class': 'data'})[0]
```

---

## 5. 데이터 선택 및 인덱싱

### 5.1 열 선택

**설명**: DataFrame에서 특정 열을 선택하는 방법입니다. 단일 열은 Series로, 여러 열은 DataFrame으로 반환됩니다.

> [!NOTE]
> 반환 타입에 대한 자세한 내용은 [5.2.4 Series vs DataFrame 반환 조건](#524-series-vs-dataframe-반환-조건)을 참조하세요.

**사용 사례**:
- 특정 변수(열)만 추출하여 분석
- 데이터 전처리 (필요한 열만 선택)
- 특성(feature) 선택 (머신러닝)
- 데이터 시각화를 위한 열 선택
- 계산에 필요한 열만 추출

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희'],
    '나이': [25, 30, 28],
    '직업': ['개발자', '디자이너', '개발자'],
    '급여': [3000, 4000, 3500]
})

# 단일 열 선택 (Series 반환)
print(df['이름'])
print(df.이름)  # 같은 결과 (공백 없는 열명만 가능)

# 여러 열 선택 (DataFrame 반환)
print(df[['이름', '나이']])

# 열 슬라이싱
print(df.loc[:, '이름':'나이'])
```

### 5.2 행 선택

**설명**: DataFrame에서 특정 행을 선택하는 방법입니다. `loc`는 라벨 기반, `iloc`는 위치 기반 인덱싱을 사용합니다.

> [!NOTE]
> - 인덱싱 방법 비교: [5.2.1 인덱싱 방법 비교](#521-인덱싱-방법-비교-기본-인덱싱-vs-loc-vs-iloc)
> - 슬라이싱 끝점: [5.2.2 슬라이싱 끝점 포함 여부](#522-슬라이싱-끝점-포함-여부-정리-중요)
> - 체인 인덱싱 주의: [5.2.3 연속된 인덱싱 주의](#523-연속된-인덱싱-주의-00-vs-0-0)

**사용 사례**:
- 특정 행 데이터 추출
- 범위의 행 선택
- 첫/마지막 행 확인
- 샘플 데이터 추출
- 데이터 검증

```python
# 라벨로 행 선택
print(df.loc[0])        # 첫 번째 행 (Series)
print(df.loc[0:2])      # 0~2행 (DataFrame)

# 위치로 행 선택
print(df.iloc[0])       # 첫 번째 행
print(df.iloc[0:2])     # 0~1행 (끝 미포함)
print(df.iloc[[0, 2]])  # 0, 2행

# 첫 번째 행과 마지막 행
print(df.iloc[0])       # 첫 행
print(df.iloc[-1])      # 마지막 행
```

### 5.2.1 인덱싱 방법 비교: 기본 인덱싱 vs loc vs iloc

**설명**: Pandas에서 데이터를 선택하는 세 가지 주요 방법의 차이점을 이해하는 것이 중요합니다. 각 방법은 다른 상황에서 사용되며, 혼동하면 예상치 못한 결과를 얻을 수 있습니다.

#### 기본 인덱싱 (df[...])

**특징**:
- 열 선택에 주로 사용
- 행 선택 시 라벨 기반으로 동작하지만 모호할 수 있음
- 슬라이싱 시 끝점 포함 (inclusive)

**사용 시나리오**:
- 열 선택 (가장 일반적)
- 단일 열: `df['열이름']` 또는 `df.열이름`
- 여러 열: `df[['열1', '열2']]`

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '나이': [25, 30, 28, 35],
    '급여': [3000, 4000, 3500, 5000]
}, index=[0, 1, 2, 3])

# 열 선택 (기본 인덱싱의 주요 용도)
print(df['이름'])        # 단일 열 선택
print(df[['이름', '나이']])  # 여러 열 선택

# 행 선택 (권장하지 않음 - 모호함)
print(df[0:2])  # 0~1행 선택 (슬라이싱, 끝점 미포함)
# 주의: 기본 인덱싱으로 행 선택은 권장하지 않습니다!
```

#### loc - 라벨 기반 인덱싱

**특징**:
- **라벨(인덱스 이름) 기반**으로 선택
- 슬라이싱 시 **끝점 포함** (inclusive)
- 행과 열 모두 라벨로 지정
- 인덱스가 정수여도 라벨로 취급

**사용 시나리오**:
- 인덱스 이름으로 행 선택
- 범위 선택 시 끝점 포함이 필요할 때
- 명시적인 라벨 기반 접근

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '나이': [25, 30, 28, 35],
    '급여': [3000, 4000, 3500, 5000]
}, index=[0, 1, 2, 3])

# 단일 행 선택
print(df.loc[0])  # 인덱스 0인 행 (Series 반환)

# 범위 선택 (끝점 포함!)
print(df.loc[0:2])  # 인덱스 0, 1, 2 행 모두 포함 (3개 행)
# 결과: 0, 1, 2 행

# 행과 열 동시 선택
print(df.loc[0:2, '이름':'나이'])  # 0~2행, 이름~나이 열

# 불리언 인덱싱
print(df.loc[df['나이'] > 25])  # 조건에 맞는 행 선택

# 리스트로 여러 행/열 선택
print(df.loc[[0, 2], ['이름', '급여']])  # 0, 2행과 이름, 급여 열
```

**인덱스가 문자열인 경우**:
```python
df_str = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희'],
    '나이': [25, 30, 28]
}, index=['a', 'b', 'c'])

print(df_str.loc['a'])        # 인덱스 'a'인 행
print(df_str.loc['a':'c'])    # 'a'부터 'c'까지 (끝점 포함, 3개 행)
```

#### iloc - 위치 기반 인덱싱

**특징**:
- **정수 위치(0부터 시작)** 기반으로 선택
- 슬라이싱 시 **끝점 미포함** (exclusive, Python 리스트와 동일)
- 인덱스 이름과 무관하게 위치로만 접근
- 음수 인덱스 사용 가능

**사용 시나리오**:
- 위치 기반 접근이 필요할 때
- 처음/끝 N개 행 선택
- 인덱스 이름을 모를 때
- Python 리스트처럼 동작해야 할 때

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '나이': [25, 30, 28, 35],
    '급여': [3000, 4000, 3500, 5000]
}, index=[0, 1, 2, 3])

# 단일 행 선택
print(df.iloc[0])  # 첫 번째 행 (위치 0)

# 범위 선택 (끝점 미포함!)
print(df.iloc[0:2])  # 위치 0, 1 행만 (2개 행)
# 결과: 0, 1 행만 (2번째 행은 미포함)

# 행과 열 동시 선택
print(df.iloc[0:2, 0:2])  # 0~1행, 0~1열

# 음수 인덱스 사용
print(df.iloc[-1])      # 마지막 행
print(df.iloc[-2:])     # 마지막 2개 행

# 리스트로 여러 행/열 선택
print(df.iloc[[0, 2], [0, 2]])  # 0, 2행과 0, 2열
```

#### 주요 차이점 요약

| 특징 | 기본 인덱싱 | loc | iloc |
|------|------------|-----|------|
| **기준** | 열: 라벨, 행: 모호함 | 라벨(인덱스 이름) | 정수 위치 |
| **슬라이싱 끝점** | 행: 미포함, 열: 포함 | **포함** (inclusive) | **미포함** (exclusive) |
| **주요 용도** | 열 선택 | 라벨 기반 행/열 선택 | 위치 기반 행/열 선택 |
| **음수 인덱스** | 지원 안 함 | 지원 안 함 | **지원** |
| **불리언 인덱싱** | 지원 | **지원** | 지원 안 함 |

#### 실전 비교 예제

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수', '최지영'],
    '나이': [25, 30, 28, 35, 22],
    '급여': [3000, 4000, 3500, 5000, 2500]
}, index=[0, 1, 2, 3, 4])

print("원본 데이터:")
print(df)
#     이름  나이   급여
# 0  홍길동  25  3000
# 1  김철수  30  4000
# 2  이영희  28  3500
# 3  박민수  35  5000
# 4  최지영  22  2500

# 1. 범위 선택 비교
print("\n1. 범위 선택 비교:")
print("df.loc[0:2]:")      # 끝점 포함 → 0, 1, 2 행 (3개)
print(df.loc[0:2])
print("\ndf.iloc[0:2]:")    # 끝점 미포함 → 0, 1 행 (2개)
print(df.iloc[0:2])

# 2. 마지막 행 선택
print("\n2. 마지막 행 선택:")
print("df.loc[4]:")        # 인덱스 4인 행
print(df.loc[4])
print("\ndf.iloc[-1]:")     # 마지막 위치의 행
print(df.iloc[-1])

# 3. 행과 열 동시 선택
print("\n3. 행과 열 동시 선택:")
print("df.loc[0:2, '이름':'나이']:")  # 라벨 기반
print(df.loc[0:2, '이름':'나이'])
print("\ndf.iloc[0:2, 0:2]:")         # 위치 기반
print(df.iloc[0:2, 0:2])

# 4. 조건부 선택 (loc만 가능)
print("\n4. 조건부 선택:")
print("df.loc[df['나이'] > 25]:")  # loc 사용
print(df.loc[df['나이'] > 25])
# iloc는 불리언 인덱싱 직접 지원 안 함
# 대신: df.iloc[(df['나이'] > 25).values] 사용 가능
```

> [!NOTE]
> **인덱싱 관련 권장사항 및 주의사항**은 [5.5 인덱싱 권장사항 요약](#55-인덱싱-권장사항-요약) 섹션을 참조하세요.

#### 5.2.2 슬라이싱 끝점 포함 여부 정리 (중요)

Pandas 슬라이싱에서 가장 혼동하기 쉬운 부분은 **"끝점(Stop)을 포함하는가?"**입니다. 이는 인덱싱 방식(라벨 vs 위치)에 따라 다릅니다.

| 구분 | 인덱싱 방식 | 끝점 포함 여부 | 예시 | 비고 |
|------|-------------|----------------|------|------|
| **문자열 (라벨)** | `loc`, `df['A':'B']` | **포함 (Inclusive)** | `'A':'C'` → 'A', 'B', 'C' 모두 포함 | 라벨은 순서를 명확히 알기 어렵기 때문에 끝까지 포함하는 것이 직관적임 |
| **숫자 (위치)** | `iloc`, `df[0:3]` | **미포함 (Exclusive)** | `0:3` → 0, 1, 2 (3은 미포함) | Python 리스트 슬라이싱과 동일한 방식 |

**예제 코드로 비교**:

```python
df = pd.DataFrame({'A': [1, 2, 3, 4]}, index=['a', 'b', 'c', 'd'])

# 1. 문자열(라벨) 슬라이싱 -> 끝점 포함
print(df.loc['a':'c'])
# 결과: a, b, c 행 (3개)

# 2. 숫자(위치) 슬라이싱 -> 끝점 미포함
print(df.iloc[0:2])
# 결과: 0, 1 행 (2개) - 2번 행(c)은 포함되지 않음
```

> [!IMPORTANT]
> **기억 팁**:
> - **이름(라벨)**을 부를 때는 "A부터 C까지 다 줘"라고 하므로 **C도 포함**됩니다.
> - **번호(위치)**를 셀 때는 Python의 기본 규칙(0부터 시작, 끝은 미포함)을 따릅니다.

#### 5.2.3 연속된 인덱싱 주의 (`[0][0]` vs `[0, 0]`)

**체인 인덱싱(Chained Indexing)**은 인덱싱 연산을 연속으로 사용하는 것을 말합니다. 이는 **성능 문제와 예측 불가능한 동작**을 야기할 수 있어 피해야 합니다.

| 구분 | 문법 | 동작 | 문제점 |
|------|------|------|--------|
| **체인 인덱싱**<br>(권장하지 않음) | `df[0][0]`<br>`df['A'][0]` | 2번의 독립적인 인덱싱 연산 수행 | - 성능 저하<br>- 중간에 복사본이 생성될 수 있음<br>- SettingWithCopyWarning 발생 가능 |
| **단일 인덱싱**<br>(권장) | `df.iloc[0, 0]`<br>`df.loc[0, 'A']` | 1번의 인덱싱 연산으로 직접 접근 | - 성능 우수<br>- 명시적이고 안전<br>- 경고 없음 |

**예제 코드로 비교**:

```python
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6]
})

# ❌ 체인 인덱싱 (권장하지 않음)
value = df['A'][0]  # 2번의 연산: 먼저 'A' 열 선택 → 그 다음 0번 행 선택
# 문제: 중간 객체가 복사본일 수 있어 값 할당 시 원본이 변경 안 될 수 있음

# ✅ 단일 인덱싱 (권장)
value = df.loc[0, 'A']  # 1번의 연산으로 직접 접근
value = df.iloc[0, 0]   # 위치 기반으로 직접 접근
```

**값 할당 시 문제**:

```python
# ❌ 체인 인덱싱으로 값 할당 (위험!)
df['A'][0] = 999  # SettingWithCopyWarning 발생 가능
# 원본이 변경될 수도, 안 될 수도 있음 (예측 불가)

# ✅ 명시적 인덱싱으로 값 할당 (안전)
df.loc[0, 'A'] = 999  # 항상 원본을 변경
```

> [!WARNING]
> **체인 인덱싱은 절대 피하세요!**
> - 읽기에서도 성능이 떨어집니다.
> - 쓰기에서는 동작이 예측 불가능합니다.
> - 항상 `loc` 또는 `iloc`를 사용하세요.

#### 5.2.4 Series vs DataFrame 반환 조건

인덱싱 결과가 **Series**로 반환되는지 **DataFrame**으로 반환되는지 이해하는 것은 후속 작업에서 중요합니다.

| 선택 방법 | 반환 타입 | 예시 |
|-----------|-----------|------|
| **단일 열 선택** | Series | `df['A']`, `df.A` |
| **여러 열 선택** | DataFrame | `df[['A', 'B']]` |
| **단일 행 선택** (loc/iloc) | Series | `df.loc[0]`, `df.iloc[0]` |
| **여러 행 선택** | DataFrame | `df.loc[0:2]`, `df.iloc[0:2]` |
| **행과 열 동시 선택 (단일 값)** | 스칼라 | `df.loc[0, 'A']`, `df.iloc[0, 0]` |
| **행과 열 동시 선택 (범위)** | Series 또는 DataFrame | `df.loc[0, :]` (Series), `df.loc[0:1, :]` (DataFrame) |

**예제 코드**:

```python
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6],
    'C': [7, 8, 9]
})

# Series 반환
series1 = df['A']              # 단일 열
series2 = df.loc[0]            # 단일 행
series3 = df.loc[0, :]         # 단일 행 (명시적)
print(type(series1))  # <class 'pandas.core.series.Series'>

# DataFrame 반환
df1 = df[['A', 'B']]           # 여러 열
df2 = df.loc[0:1]              # 여러 행
df3 = df.loc[[0], :]           # 단일 행을 리스트로 (DataFrame 유지)
print(type(df1))      # <class 'pandas.core.frame.DataFrame'>

# 스칼라 반환
scalar = df.loc[0, 'A']        # 단일 값
print(type(scalar))   # <class 'numpy.int64'> (또는 int)
```

> [!TIP]
> **DataFrame을 유지하고 싶다면?**
> - 단일 열: `df[['A']]` (이중 대괄호)
> - 단일 행: `df.loc[[0], :]` 또는 `df.iloc[[0], :]` (리스트로 감싸기)

### 5.3 행과 열 동시 선택

**설명**: 행과 열을 동시에 지정하여 특정 부분의 데이터를 선택합니다. `loc`와 `iloc`를 사용하여 다양한 방식으로 접근할 수 있습니다.

> [!NOTE]
> `loc`와 `iloc`의 차이는 [5.2.1 인덱싱 방법 비교](#521-인덱싱-방법-비교-기본-인덱싱-vs-loc-vs-iloc)를 참조하세요.

**사용 사례**:
- 특정 셀 값 접근
- 부분 데이터프레임 추출
- 데이터 서브셋 생성
- 특정 행과 열만 선택
- 데이터 검증 및 확인

```python
# loc: 라벨 기반 인덱싱
print(df.loc[0, '이름'])           # 단일 값
print(df.loc[0:1, '이름':'나이'])  # 범위 선택
print(df.loc[[0, 2], ['이름', '직업']])  # 특정 행, 열

# iloc: 위치 기반 인덱싱
print(df.iloc[0, 0])               # 첫 행, 첫 열
print(df.iloc[0:2, 0:2])           # 0~1행, 0~1열
print(df.iloc[[0, 2], [0, 2]])     # 특정 행, 열
```

### 5.4 인덱싱과 복사/뷰 (Copy vs View)

**설명**: Pandas에서 인덱싱을 통해 데이터를 선택할 때, 반환되는 객체가 원본 데이터의 **뷰(View)**인지 **복사본(Copy)**인지 이해하는 것이 중요합니다. 이는 데이터 수정 시 예상치 못한 결과를 방지하는 데 필수적입니다.

> [!NOTE]
> 인덱싱 권장사항은 [5.5 인덱싱 권장사항 요약](#55-인덱싱-권장사항-요약)을 참조하세요.

**뷰 (View)**
- 원본 데이터를 참조하는 객체
- 뷰를 수정하면 원본도 함께 변경됨
- 메모리 효율적 (데이터 복사 없음)

**복사본 (Copy)**
- 원본 데이터의 독립적인 복사본
- 복사본을 수정해도 원본은 변경되지 않음
- 메모리 사용량 증가

#### 5.4.1 뷰가 생성되는 경우

**단일 열 선택 (Series)**
- 단일 열을 선택하면 항상 뷰를 반환합니다.
- 뷰를 수정하면 원본 DataFrame도 변경됩니다.

```python
df = pd.DataFrame({
    'A': [1, 2, 3, 4],
    'B': [10, 20, 30, 40]
})

# 단일 열 선택 → 뷰
series_view = df['A']
print(series_view is df['A'])  # True (같은 객체)

# 뷰 수정 → 원본도 변경됨
series_view.iloc[0] = 999
print(df)
#      A   B
# 0  999  10  ← 원본도 변경됨!
# 1    2  20
# 2    3  30
# 3    4  40
```

**슬라이싱 (일부 경우)**
- 연속적인 슬라이싱은 뷰를 반환할 수 있습니다.
- 하지만 보장되지 않으므로 주의가 필요합니다.

```python
df = pd.DataFrame({
    'A': [1, 2, 3, 4, 5],
    'B': [10, 20, 30, 40, 50]
})

# 연속적인 슬라이싱 → 뷰일 수 있음
slice_view = df[0:3]  # 뷰일 수 있음 (보장 안 됨)

# ⚠️ 주의: 뷰 수정 시 원본도 변경될 수 있음
# slice_view.iloc[0, 0] = 999  # 원본도 변경될 수 있음
```

#### 5.4.2 복사본이 생성되는 경우

**리스트 인덱싱 (팬시 인덱싱)**
- 리스트로 여러 행/열을 선택하면 항상 복사본을 반환합니다.

```python
df = pd.DataFrame({
    'A': [1, 2, 3, 4],
    'B': [10, 20, 30, 40]
})

# 리스트 인덱싱 → 복사본
df_copy = df[[0, 2]]  # 복사본
df_copy.iloc[0, 0] = 999
print(df)
#    A   B
# 0  1  10  ← 원본은 변경 안 됨
# 1  2  20
# 2  3  30
# 3  4  40
```

**불리언 인덱싱**
- 조건부 선택은 복사본을 반환합니다.

```python
# 불리언 인덱싱 → 복사본
df_filtered = df[df['A'] > 2]  # 복사본
df_filtered.iloc[0, 0] = 999
print(df)
#    A   B  ← 원본은 변경 안 됨
# 0  1  10
# 1  2  20
# 2  3  30
# 3  4  40
```

**명시적 복사**
- `copy()` 메서드를 사용하여 명시적으로 복사본을 생성할 수 있습니다.

```python
# 명시적 복사
df_copy = df.copy()  # 깊은 복사 (deep copy)
df_copy = df.copy(deep=False)  # 얕은 복사 (shallow copy)

# 복사본 수정 → 원본 변경 안 됨
df_copy.iloc[0, 0] = 999
print(df)  # 원본은 변경 안 됨
```

#### 5.4.3 인덱싱 방법별 복사/뷰 동작

**`loc` 인덱싱**
- 단일 값 선택: 뷰 또는 스칼라 값
- 슬라이싱: 뷰일 수 있음 (보장 안 됨)
- 리스트 인덱싱: 복사본

```python
df = pd.DataFrame({
    'A': [1, 2, 3, 4],
    'B': [10, 20, 30, 40]
})

# loc 슬라이싱 → 뷰일 수 있음
view_loc = df.loc[0:2, 'A']  # 뷰일 수 있음

# loc 리스트 인덱싱 → 복사본
copy_loc = df.loc[[0, 2], 'A']  # 복사본
```

**`iloc` 인덱싱**
- 단일 값 선택: 뷰 또는 스칼라 값
- 슬라이싱: 뷰일 수 있음 (보장 안 됨)
- 리스트 인덱싱: 복사본

```python
# iloc 슬라이싱 → 뷰일 수 있음
view_iloc = df.iloc[0:2, 0]  # 뷰일 수 있음

# iloc 리스트 인덱싱 → 복사본
copy_iloc = df.iloc[[0, 2], 0]  # 복사본
```

#### 5.4.4 복사/뷰 확인 방법

**`_is_view` 속성 (Pandas 내부)**
- Pandas 내부 속성으로 뷰 여부를 확인할 수 있습니다.
- 공식 API가 아니므로 주의가 필요합니다.

```python
# ⚠️ 내부 속성 (공식 API 아님)
series_view = df['A']
# print(series_view._is_view)  # True 또는 False (내부 속성)
```

**실제 테스트 방법**
- 원본을 수정하고 선택한 객체가 변경되는지 확인합니다.

```python
df = pd.DataFrame({'A': [1, 2, 3], 'B': [10, 20, 30]})
original_value = df.iloc[0, 0]

# 선택
selected = df['A']

# 원본 수정
df.iloc[0, 0] = 999

# 선택한 객체 확인
if selected.iloc[0] == 999:
    print("뷰입니다 (원본과 연결됨)")
else:
    print("복사본입니다 (원본과 독립적)")
```

#### 5.4.5 SettingWithCopyWarning

**경고 발생 상황**
- 뷰에 값을 할당하려고 할 때 발생합니다.
- 원본 데이터가 의도치 않게 변경될 수 있다는 경고입니다.

```python
# ⚠️ 경고 발생하는 코드
df = pd.DataFrame({
    'A': [1, 2, 3, 4],
    'B': [10, 20, 30, 40]
})

# 체인 인덱싱으로 뷰에 할당 → 경고 발생
df[df['A'] > 2]['B'] = 999  # SettingWithCopyWarning!

# 올바른 방법 1: loc 사용
df.loc[df['A'] > 2, 'B'] = 999  # 경고 없음

# 올바른 방법 2: 명시적 복사 후 수정
df_filtered = df[df['A'] > 2].copy()
df_filtered['B'] = 999
```

#### 5.4.6 실전 예제와 권장 사항

**예제 1: 뷰 수정으로 인한 문제**

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희'],
    '나이': [25, 30, 28],
    '급여': [3000, 4000, 3500]
})

# ⚠️ 문제: 뷰를 수정하면 원본도 변경됨
names = df['이름']  # 뷰
names.iloc[0] = '홍길동수정'
print(df)  # 원본도 변경됨!

# ✅ 해결: 복사본 사용
names = df['이름'].copy()  # 복사본
names.iloc[0] = '홍길동수정'
print(df)  # 원본은 변경 안 됨
```

**예제 2: 필터링 후 수정**

```python
# ⚠️ 문제: 체인 인덱싱으로 할당
df[df['나이'] < 30]['급여'] = df[df['나이'] < 30]['급여'] * 1.1
# SettingWithCopyWarning 발생

# ✅ 해결 1: loc 사용
df.loc[df['나이'] < 30, '급여'] = df.loc[df['나이'] < 30, '급여'] * 1.1

# ✅ 해결 2: 복사본 사용
young = df[df['나이'] < 30].copy()
young['급여'] = young['급여'] * 1.1
# 원본 df는 변경 안 됨
```

#### 5.4.7 객체 비교와 `id()` 함수 주의사항 (메모리 재활용)

`loc`이나 `iloc`을 사용하여 데이터를 선택할 때, 서로 다른 객체임에도 불구하고 `id()` 함수(메모리 주소)의 결과가 같게 나오는 경우가 있어 혼동을 줄 수 있습니다. 이는 Python의 **메모리 재활용 메커니즘** 때문입니다.

**현상**:
```python
# 서로 다른 객체인지 확인 (False)
print(df.iloc[0] is df.iloc[0])  # False (항상 새로운 객체 생성)

# 주소값 확인 (같을 수 있음!)
print(id(df.iloc[0]))  # 예: 1407362028
print(id(df.iloc[0]))  # 예: 1407362028 (동일한 주소)
```

**원인 (임시 객체와 메모리 재활용)**:
1. `df.iloc[0]`이 실행되면 새로운 Series **임시 객체**가 생성되고 메모리에 할당됩니다.
2. `id()` 함수가 이 객체의 메모리 주소를 반환합니다.
3. `id()` 함수 호출이 끝나면, 생성된 임시 객체는 더 이상 참조되지 않으므로 **즉시 소멸(Garbage Collection)**됩니다.
4. 다음 줄에서 다시 `df.iloc[0]`을 실행하면, Python은 방금 해제된 **동일한 메모리 공간을 재활용**하여 새로운 객체를 할당할 가능성이 높습니다.
5. 결과적으로 서로 다른 시점에 생성된 두 객체가 우연히 같은 메모리 주소를 사용하게 되어 `id()` 값이 같아 보입니다.

**올바른 비교 방법**:
- **객체 동일성(Identity)** 비교: `is` 연산자를 사용하세요.
  - `obj1 is obj2` (같은 객체인가?)
- **값 동등성(Equality)** 비교: `==` 연산자나 `.equals()` 메서드를 사용하세요.
  - `obj1.equals(obj2)` (내용이 같은가?)
- **주의**: `id()` 값으로 객체의 생명주기나 동일성을 판단하지 마세요. 특히 임시 객체의 경우 더욱 그렇습니다.

> [!NOTE]
> 인덱싱 및 복사/뷰 관련 권장사항은 [5.5 인덱싱 권장사항 요약](#55-인덱싱-권장사항-요약) 섹션을 참조하세요.

### 5.5 인덱싱 권장사항 요약

이 섹션은 Pandas 인덱싱 사용 시 자주 발생하는 문제와 권장사항을 요약합니다.

#### 1. **기본 인덱싱으로 행 선택은 피하세요**
```python
# ❌ 권장하지 않음
df[0:2]  # 모호하고 예상치 못한 결과 가능

# ✅ 권장
df.loc[0:2]   # 명확한 라벨 기반
df.iloc[0:2]  # 명확한 위치 기반
```

#### 2. **슬라이싱 끝점 차이를 항상 확인하세요**
```python
# loc: 끝점 포함
df.loc[0:2]   # 0, 1, 2 행 (3개)

# iloc: 끝점 미포함
df.iloc[0:2]  # 0, 1 행 (2개)
```
→ 자세한 내용은 [5.2.2 슬라이싱 끝점 포함 여부 정리](#522-슬라이싱-끝점-포함-여부-정리-중요) 참조

#### 3. **체인 인덱싱을 절대 사용하지 마세요**
```python
# ❌ 체인 인덱싱 (위험!)
df['A'][0] = 999          # SettingWithCopyWarning 발생
df[df['나이'] > 25]['급여'] = 5000  # 원본이 변경 안 될 수 있음

# ✅ 명시적 인덱싱 (안전)
df.loc[0, 'A'] = 999
df.loc[df['나이'] > 25, '급여'] = 5000
```
→ 자세한 내용은 [5.2.3 연속된 인덱싱 주의](#523-연속된-인덱싱-주의-00-vs-0-0) 참조

#### 4. **불리언 인덱싱은 `loc` 사용**
```python
# ✅ 권장
df.loc[df['나이'] > 25]

# ❌ iloc는 불리언 배열을 직접 받지 않음
# 대신: df.iloc[(df['나이'] > 25).values]
```

#### 5. **원본 보존이 필요하면 명시적으로 복사하세요**
```python
# ✅ 복사본 생성
df_copy = df.copy()  # 원본과 독립적

# 또는 특정 작업 후 복사
filtered = df[df['나이'] > 25].copy()
```

#### 6. **값 수정 시 `loc` 또는 `iloc` 사용**
```python
# ✅ 권장
df.loc[조건, '열'] = 값

# ❌ 피하기
df[조건]['열'] = 값  # 체인 인덱싱
```

#### 7. **SettingWithCopyWarning을 무시하지 마세요**
- 이 경고는 코드가 예측 불가능하게 동작할 수 있음을 알려줍니다
- 경고가 발생하면 코드를 수정하여 해결하세요

#### 8. **인덱스가 정수일 때 혼동 주의**
```python
# 인덱스가 [0, 1, 2, 3]일 때
df.loc[0:2]   # 인덱스 0, 1, 2 (3개 행) - 라벨로 취급
df.iloc[0:2]  # 위치 0, 1 (2개 행) - 위치로 취급
```

#### 9. **뷰/복사본 동작은 보장되지 않습니다**
- Pandas 버전에 따라 뷰/복사본 동작이 달라질 수 있습니다
- 안전을 위해 명시적 복사를 권장합니다
- 자세한 내용은 [5.4 인덱싱과 복사/뷰](#54-인덱싱과-복사뷰-copy-vs-view) 참조

#### 10. **메모리 효율성 vs 안전성**
- **뷰**: 메모리 효율적이지만 원본 변경 위험
- **복사본**: 안전하지만 메모리 사용량 증가
- 상황에 따라 적절히 선택하세요

---

### 5.6 조건부 선택

**설명**: 조건에 따라 데이터를 필터링하여 선택합니다. 불리언 인덱싱을 사용하여 복잡한 조건도 표현할 수 있습니다.

> [!NOTE]
> 불리언 인덱싱은 `loc`를 사용해야 합니다. 자세한 내용은 [5.5 인덱싱 권장사항 요약 #4](#4-불리언-인덱싱은-loc-사용)를 참조하세요.

**사용 사례**:
- 조건에 맞는 데이터 추출
- 복합 조건 필터링
- 특정 값 포함 여부 확인
- 문자열 패턴 매칭
- 데이터 서브셋 생성

```python
# 단일 조건
print(df[df['나이'] > 25])

# 여러 조건 (AND)
print(df[(df['나이'] > 25) & (df['급여'] > 3000)])

# 여러 조건 (OR)
print(df[(df['나이'] > 30) | (df['급여'] < 3500)])

# isin: 포함 여부
print(df[df['직업'].isin(['개발자', '디자이너'])])

# 문자열 조건
print(df[df['이름'].str.contains('홍')])
```

---

### 5.7 멀티인덱스 (MultiIndex)

#### 5.7.1 멀티인덱스 개념

**설명**: 멀티인덱스(MultiIndex)는 하나의 축(행 또는 열)에 **여러 레벨의 인덱스**를 가질 수 있게 해주는 기능입니다. 이를 통해 고차원 데이터를 2차원 DataFrame으로 표현할 수 있습니다.

**사용 사례**:
- 시계열 데이터 + 지역/카테고리별 분석
- 다차원 데이터를 평면 테이블로 표현
- 계층적 그룹화 결과 저장
- 피벗 테이블 결과
- 복잡한 데이터 구조 정리

**장점**:
- 고차원 데이터를 효율적으로 저장
- 계층적 데이터 접근 가능
- 그룹화 및 집계 작업에 유용
- 메모리 효율적

```python
import pandas as pd
import numpy as np

# 멀티인덱스 예시
index = pd.MultiIndex.from_tuples([
    ('서울', '강남구'),
    ('서울', '강북구'),
    ('부산', '해운대구'),
    ('부산', '사하구')
], names=['시', '구'])

df = pd.DataFrame({
    '인구': [500000, 300000, 400000, 250000],
    '면적': [39.5, 23.6, 51.4, 40.9]
}, index=index)

print(df)
#              인구   면적
# 시   구                
# 서울 강남구  500000  39.5
#     강북구  300000  23.6
# 부산 해운대구 400000  51.4
#     사하구  250000  40.9
```

#### 5.7.2 멀티인덱스 생성

**1. `pd.MultiIndex.from_tuples()`: 튜플 리스트로 생성**

```python
# 튜플 리스트로 멀티인덱스 생성
index = pd.MultiIndex.from_tuples([
    ('2024', 'Q1'),
    ('2024', 'Q2'),
    ('2025', 'Q1'),
    ('2025', 'Q2')
], names=['연도', '분기'])

df = pd.DataFrame({
    '매출': [100, 120, 130, 150]
}, index=index)
```

**2. `pd.MultiIndex.from_arrays()`: 배열 리스트로 생성**

```python
# 각 레벨을 별도 배열로 제공
arrays = [
    ['서울', '서울', '부산', '부산'],
    ['강남', '강북', '해운대', '사하']
]
index = pd.MultiIndex.from_arrays(arrays, names=['시', '구'])
```

**3. `pd.MultiIndex.from_product()`: 조합으로 생성**

```python
# 모든 조합 생성 (Cartesian Product)
years = ['2024', '2025']
quarters = ['Q1', 'Q2', 'Q3', 'Q4']
index = pd.MultiIndex.from_product([years, quarters], names=['연도', '분기'])
# 결과: ('2024', 'Q1'), ('2024', 'Q2'), ..., ('2025', 'Q4')
```

**4. `set_index()`: 기존 열을 멀티인덱스로 설정**

```python
df = pd.DataFrame({
    '시': ['서울', '서울', '부산', '부산'],
    '구': ['강남', '강북', '해운대', '사하'],
    '인구': [500000, 300000, 400000, 250000]
})

# 여러 열을 멀티인덱스로 설정
df_multi = df.set_index(['시', '구'])
print(df_multi)
#              인구
# 시   구          
# 서울 강남   500000
#     강북   300000
# 부산 해운대 400000
#     사하   250000
```

#### 5.7.3 멀티인덱스 데이터 선택

**1. 첫 번째 레벨로 선택**

```python
# 첫 번째 레벨(시)로 선택
print(df_multi.loc['서울'])
#       인구
# 구         
# 강남  500000
# 강북  300000
```

**2. 여러 레벨로 선택 (튜플 사용)**

```python
# 튜플로 정확한 인덱스 지정
print(df_multi.loc[('서울', '강남')])
# 인구    500000
# Name: (서울, 강남), dtype: int64

# 여러 행 선택
print(df_multi.loc[[('서울', '강남'), ('부산', '해운대')]])
```

**3. 슬라이싱**

```python
# 첫 번째 레벨 슬라이싱
print(df_multi.loc['서울':'부산'])

# 두 번째 레벨은 슬라이시 객체 사용
idx = pd.IndexSlice
print(df_multi.loc[idx[:, '강남'], :])  # 모든 시의 '강남'
```

**4. `xs()` 메서드: 특정 레벨에서 값 선택**

```python
# 두 번째 레벨(구)에서 '강남' 선택
print(df_multi.xs('강남', level='구'))
#       인구
# 시         
# 서울  500000

# 첫 번째 레벨(시)에서 '서울' 선택
print(df_multi.xs('서울', level='시'))
#       인구
# 구         
# 강남  500000
# 강북  300000
```

#### 5.7.4 멀티인덱스 조작

**1. `swaplevel()`: 레벨 순서 교환**

```python
# 레벨 순서 바꾸기
df_swapped = df_multi.swaplevel('시', '구')
print(df_swapped)
#              인구
# 구     시         
# 강남   서울  500000
# 강북   서울  300000
# 해운대 부산  400000
# 사하   부산  250000
```

**2. `reset_index()`: 멀티인덱스를 일반 열로 변환**

```python
# 멀티인덱스 제거 (인덱스를 열로)
df_reset = df_multi.reset_index()
print(df_reset)
#     시      구    인구
# 0  서울   강남  500000
# 1  서울   강북  300000
# 2  부산  해운대 400000
# 3  부산   사하  250000
```

**3. `sort_index()`: 멀티인덱스 정렬**

```python
# 특정 레벨로 정렬
df_sorted = df_multi.sort_index(level='구')

# 여러 레벨로 정렬
df_sorted = df_multi.sort_index(level=['시', '구'], ascending=[True, False])
```

**4. `stack()`/`unstack()`: 인덱스와 열 변환**

```python
# unstack: 행 인덱스를 열로 변환
df_unstacked = df_multi.unstack(level='구')
print(df_unstacked)
#           인구                    
# 구        강남    강북  사하  해운대
# 시                              
# 부산      NaN     NaN  250000  400000
# 서울   500000  300000     NaN     NaN

# stack: 열을 행 인덱스로 변환
df_stacked = df_unstacked.stack()
```

#### 5.7.5 실전 예제

**예제 1: 시계열 + 지역별 데이터**

```python
# 날짜 + 지역 멀티인덱스
dates = pd.date_range('2024-01-01', periods=3)
regions = ['서울', '부산', '대구']
index = pd.MultiIndex.from_product([dates, regions], names=['날짜', '지역'])

df_sales = pd.DataFrame({
    '매출': np.random.randint(100, 500, size=9),
    '방문자': np.random.randint(50, 200, size=9)
}, index=index)

# 특정 날짜의 모든 지역 데이터
print(df_sales.loc['2024-01-01'])

# 특정 지역의 시계열 데이터
print(df_sales.xs('서울', level='지역'))
```

**예제 2: 그룹화와 멀티인덱스**

```python
df = pd.DataFrame({
    '지역': ['서울', '서울', '부산', '부산', '서울', '부산'],
    '제품': ['A', 'B', 'A', 'B', 'A', 'B'],
    '매출': [100, 150, 120, 180, 110, 160]
})

# 그룹화 결과는 자동으로 멀티인덱스
grouped = df.groupby(['지역', '제품'])['매출'].sum()
print(grouped)
# 지역  제품
# 부산  A     120
#      B     340
# 서울  A     210
#      B     150
# Name: 매출, dtype: int64

# 멀티인덱스를 활용한 분석
print(grouped.loc['서울'])  # 서울의 제품별 매출
print(grouped.xs('A', level='제품'))  # 모든 지역의 제품A 매출
```

> [!TIP]
> **멀티인덱스 사용 팁**:
> - `pd.IndexSlice`를 사용하면 복잡한 슬라이싱이 쉬워집니다
> - `xs()` 메서드는 특정 레벨에서 값을 선택할 때 유용합니다
> - `stack()`/`unstack()`으로 데이터 형태를 유연하게 변경할 수 있습니다
> - 정렬(`sort_index`)을 먼저 하면 선택 성능이 향상됩니다

---

## 6. 데이터 필터링

### 6.1 조건 필터링

**설명**: 조건에 따라 데이터를 필터링하여 원하는 행만 선택합니다. 불리언 인덱싱이나 query 메서드를 사용합니다.

**사용 사례**:
- 특정 조건을 만족하는 데이터만 추출
- 이상치 제거 (범위 밖 데이터 필터링)
- 특정 그룹의 데이터 분석
- 데이터 샘플링 (조건에 맞는 샘플 선택)
- 리포트 생성 (특정 기준의 데이터만 포함)

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '나이': [25, 30, 28, 35],
    '급여': [3000, 4000, 3500, 5000]
})

# 비교 연산자
young = df[df['나이'] < 30]
high_salary = df[df['급여'] >= 4000]

# query 메서드
result = df.query('나이 > 25 and 급여 < 4500')
print(result)
```

### 6.2 문자열 필터링

**설명**: 문자열 열에 대해 패턴 매칭이나 문자열 검색을 수행하여 데이터를 필터링합니다. `.str` 접근자를 사용합니다.

**사용 사례**:
- 문자열 패턴 검색
- 이메일, 전화번호 등 형식 검증
- 특정 문자열로 시작/끝나는 데이터 찾기
- 텍스트 데이터 필터링
- 데이터 정제

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '이메일': ['hong@email.com', 'kim@email.com', 'lee@email.com', 'park@email.com']
})

# contains: 포함 여부
print(df[df['이름'].str.contains('홍')])

# startswith: 시작 문자열
print(df[df['이메일'].str.startswith('hong')])

# endswith: 끝 문자열
print(df[df['이메일'].str.endswith('.com')])

# 정규표현식
print(df[df['이메일'].str.match(r'^[a-z]+@')])
```

### 6.3 인덱스 필터링

**설명**: 인덱스를 기준으로 데이터를 필터링합니다. 인덱스를 설정한 후 라벨 기반 인덱싱을 사용할 수 있습니다.

**사용 사례**:
- 인덱스 기반 데이터 접근
- 인덱스 범위 선택
- 인덱스 패턴 매칭
- 시계열 데이터 필터링
- 이름/ID 기반 데이터 검색

```python
# 인덱스로 필터링
df_indexed = df.set_index('이름')
print(df_indexed.loc['홍길동'])

# 인덱스 슬라이싱
print(df_indexed.loc['홍길동':'이영희'])

# 인덱스 조건
print(df_indexed[df_indexed.index.str.contains('홍')])
```

---

## 7. 데이터 정렬

### 7.1 값으로 정렬

**설명**: 열의 값을 기준으로 데이터를 정렬합니다. 단일 열 또는 여러 열을 기준으로 정렬할 수 있으며, 오름차순/내림차순을 지정할 수 있습니다.

**사용 사례**:
- 데이터 정렬 (나이순, 가격순 등)
- 상위 N개 선택 전 정렬
- 리포트 생성 (정렬된 데이터)
- 데이터 분석 전 준비
- 시각화 전 정렬

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '나이': [25, 30, 28, 35],
    '급여': [3000, 4000, 3500, 5000]
})

# 단일 열로 정렬
df_sorted = df.sort_values('나이')
print(df_sorted)

# 내림차순 정렬
df_sorted = df.sort_values('나이', ascending=False)
print(df_sorted)

# 여러 열로 정렬
df_sorted = df.sort_values(['나이', '급여'], ascending=[True, False])
print(df_sorted)
```

### 7.2 인덱스로 정렬

**설명**: 인덱스를 기준으로 데이터를 정렬합니다. 인덱스가 날짜나 이름인 경우 유용합니다.

**사용 사례**:
- 인덱스 순서 정렬
- 날짜 인덱스 정렬
- 이름/ID 순서 정렬
- 데이터 재정렬
- 인덱스 기반 정렬

```python
# 인덱스 정렬
df_sorted = df.sort_index()

# 인덱스 내림차순 정렬
df_sorted = df.sort_index(ascending=False)
```

### 7.3 정렬 옵션

**설명**: 정렬 시 추가 옵션을 지정할 수 있습니다. 결측치 위치나 정렬 알고리즘을 선택할 수 있습니다.

**사용 사례**:
- 결측치 처리 (정렬 시 위치 지정)
- 안정 정렬 (같은 값의 순서 유지)
- 성능 최적화 (정렬 알고리즘 선택)
- 특수한 정렬 요구사항
- 대용량 데이터 정렬

```python
# 결측치 처리
df_sorted = df.sort_values('나이', na_position='last')  # 결측치를 마지막에

# 정렬 알고리즘 선택
df_sorted = df.sort_values('나이', kind='mergesort')  # 안정 정렬
```

---

## 8. 결측치 처리

### 8.1 결측치 확인

**설명**: 데이터에 누락된 값(NaN, None)을 확인하는 방법입니다. 데이터 품질 검사와 전처리의 첫 단계입니다.

**사용 사례**:
- 데이터 품질 검사 (누락된 데이터 확인)
- 데이터 전처리 전 현황 파악
- 결측치 패턴 분석
- 데이터 정제 계획 수립
- 리포트 작성 (데이터 완성도)

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '나이': [25, None, 28, 35],
    '급여': [3000, 4000, None, 5000]
})

# 결측치 확인
print(df.isna())        # 결측치면 True
print(df.isnull())      # isna()와 동일
print(df.notna())       # 결측치가 아니면 True

# 결측치 개수
print(df.isna().sum())  # 각 열별 결측치 개수
print(df.isna().sum().sum())  # 전체 결측치 개수
```

### 8.2 결측치 제거

**설명**: 결측치가 있는 행이나 열을 제거합니다. 데이터 품질을 향상시키거나 분석에 필요한 완전한 데이터만 남길 때 사용합니다.

**사용 사례**:
- 결측치가 많은 행/열 제거
- 완전한 데이터만 분석
- 데이터 품질 개선
- 특정 열 기준 결측치 제거
- 데이터 정제

```python
# 결측치가 있는 행 제거
df_dropped = df.dropna()
print(df_dropped)

# 모든 값이 결측치인 행만 제거
df_dropped = df.dropna(how='all')

# 특정 열에 결측치가 있는 행만 제거
df_dropped = df.dropna(subset=['나이'])

# 결측치가 있는 열 제거
df_dropped = df.dropna(axis=1)
```

### 8.3 결측치 채우기

**설명**: 결측치를 특정 값이나 통계값으로 채웁니다. 데이터 손실을 최소화하면서 분석을 진행할 수 있게 해줍니다.

**사용 사례**:
- 결측치를 기본값으로 채우기
- 통계값(평균, 중앙값)으로 채우기
- 시계열 데이터 보간
- 데이터 완성도 향상
- 분석 가능한 데이터셋 만들기

```python
# 특정 값으로 채우기
df_filled = df.fillna(0)
print(df_filled)

# 각 열별로 다른 값으로 채우기
df_filled = df.fillna({'나이': 0, '급여': 1000})

# 앞 값으로 채우기 (forward fill)
df_filled = df.fillna(method='ffill')

# 뒤 값으로 채우기 (backward fill)
df_filled = df.fillna(method='bfill')

# 평균값으로 채우기
df['나이'] = df['나이'].fillna(df['나이'].mean())

# 중앙값으로 채우기
df['급여'] = df['급여'].fillna(df['급여'].median())
```

### 8.4 보간 (Interpolation)

**설명**: 결측치를 주변 값들을 기반으로 추정하여 채웁니다. 선형 보간, 시간 기반 보간 등 다양한 방법을 사용할 수 있습니다.

**사용 사례**:
- 시계열 데이터 보간
- 연속적인 값 추정
- 자연스러운 값 채우기
- 센서 데이터 처리
- 시간 기반 데이터 보완

```python
# 선형 보간
df_interpolated = df.interpolate()

# 시계열 데이터 보간
df_interpolated = df.interpolate(method='time')
```

---

## 9. 데이터 변형 및 추가

### 9.1 열 추가

**설명**: DataFrame에 새로운 열을 추가합니다. 직접 값을 지정하거나 기존 열을 계산하여 추가할 수 있습니다.

**사용 사례**:
- 계산된 열 추가 (총합, 평균 등)
- 조건부 열 추가 (카테고리 분류)
- 파생 변수 생성
- 데이터 보강
- 특성(feature) 엔지니어링

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희'],
    '나이': [25, 30, 28],
    '급여': [3000, 4000, 3500]
})

# 새 열 추가
df['보너스'] = [300, 400, 350]
print(df)

# 계산으로 열 추가
df['총급여'] = df['급여'] + df['보너스']
print(df)

# 조건부 열 추가
df['등급'] = df['급여'].apply(lambda x: '높음' if x > 3500 else '낮음')
print(df)
```

### 9.2 열 삭제

**설명**: DataFrame에서 불필요한 열을 삭제합니다. 메모리 절약이나 필요한 열만 남길 때 사용합니다.

**사용 사례**:
- 불필요한 열 제거
- 메모리 최적화
- 특성 선택 (feature selection)
- 데이터 정제
- 민감 정보 제거

```python
# drop 메서드 (원본 유지)
df_dropped = df.drop('보너스', axis=1)
print(df_dropped)

# 여러 열 삭제
df_dropped = df.drop(['보너스', '등급'], axis=1)

# inplace=True (원본 수정)
df.drop('보너스', axis=1, inplace=True)

# del 사용
del df['등급']
```

### 9.3 행 추가

**설명**: DataFrame에 새로운 행을 추가합니다. `append` 메서드나 `loc`를 사용하여 추가할 수 있습니다.

**사용 사례**:
- 새 데이터 추가
- 데이터 업데이트
- 데이터 병합
- 점진적 데이터 수집
- 데이터 보강

```python
# append 메서드 (새 DataFrame 반환)
new_row = pd.DataFrame({'이름': ['박민수'], '나이': [35], '급여': [5000]})
df_appended = df.append(new_row, ignore_index=True)
print(df_appended)

# loc로 추가
df.loc[3] = ['박민수', 35, 5000]
```

### 9.4 행 삭제

**설명**: DataFrame에서 특정 행을 삭제합니다. 인덱스나 조건을 사용하여 삭제할 수 있습니다.

**사용 사례**:
- 이상치 제거
- 특정 조건의 행 삭제
- 데이터 정제
- 샘플 제거
- 데이터 필터링

```python
# 인덱스로 삭제
df_dropped = df.drop(0)  # 첫 번째 행 삭제

# 여러 행 삭제
df_dropped = df.drop([0, 2])

# 조건으로 삭제
df_dropped = df[df['나이'] >= 30]
```

### 9.5 열 이름 변경

**설명**: DataFrame의 열 이름을 변경합니다. 일부만 변경하거나 전체를 변경할 수 있습니다.

**사용 사례**:
- 열 이름 표준화
- 영어/한글 변환
- 명명 규칙 통일
- 가독성 향상
- 데이터 정제

```python
# rename 메서드
df_renamed = df.rename(columns={'이름': 'name', '나이': 'age'})
print(df_renamed)

# 전체 열 이름 변경
df.columns = ['name', 'age', 'salary']
print(df)
```

### 9.6 인덱스 설정

**설명**: DataFrame의 인덱스를 설정하거나 리셋합니다. 특정 열을 인덱스로 사용하면 데이터 접근이 편리해집니다.

**사용 사례**:
- 이름/ID를 인덱스로 설정
- 날짜를 인덱스로 설정 (시계열)
- 인덱스 기반 데이터 접근
- 인덱스 재설정
- 데이터 구조 변경

```python
# 인덱스를 열로 설정
df_indexed = df.set_index('이름')
print(df_indexed)

# 인덱스 리셋
df_reset = df_indexed.reset_index()
print(df_reset)

# 인덱스 이름 설정
df.index.name = '번호'
print(df)
```

### 9.7 데이터 타입 추론 (infer_objects)

**설명**: DataFrame이나 Series의 데이터 타입을 더 적절한 타입으로 추론하여 변환합니다. 주로 데이터 조작(예: `replace`, `fillna`) 후에도 여전히 `object` 타입으로 남아있는 숫자형 데이터를 실제 숫자형(int, float)으로 변환할 때 사용합니다.

**사용 사례**:
- `replace` 등으로 비수치 데이터를 숫자로 변경한 후 타입 정리
- `object` 타입으로 저장된 숫자 데이터의 타입을 올바르게 복구
- Pandas 최신 버전에서 `downcast` 옵션이 deprecated됨에 따른 대안
- 데이터 타입 최적화

```python
df = pd.DataFrame({
    'A': ['1', '-', '3'],
    'B': [1, 2, 3]
})

# '-'를 0으로 변경 (여전히 object 타입 유지 가능성 있음)
df['A'] = df['A'].replace('-', 0)
print(df.dtypes)
# A    object
# B    int64
# dtype: object

# 데이터 타입 추론 (object -> int/float)
df = df.infer_objects()
print(df.dtypes)
# A    int64 (또는 상황에 따라 float)
# B    int64
# dtype: object
```

---

## 10. 그룹화 및 집계

### 10.1 기본 그룹화

**설명**: 특정 기준(열)으로 데이터를 그룹화하여 각 그룹별로 집계 연산을 수행합니다. SQL의 GROUP BY와 유사합니다.

**사용 사례**:
- 카테고리별 통계 계산 (부서별 평균 급여)
- 시계열 데이터 집계 (월별, 일별 집계)
- 그룹별 비교 분석
- 데이터 요약 및 리포트 생성
- 계층적 데이터 분석

```python
df = pd.DataFrame({
    '부서': ['개발', '개발', '디자인', '디자인', '기획'],
    '이름': ['홍길동', '김철수', '이영희', '박민수', '최지영'],
    '급여': [3000, 3500, 4000, 4500, 5000]
})

# 단일 열로 그룹화
grouped = df.groupby('부서')
print(grouped.groups)  # 그룹 정보

# 그룹별 평균
print(grouped.mean())

# 그룹별 합계
print(grouped.sum())
```

### 10.2 집계 함수

**설명**: 그룹화된 데이터에 여러 집계 함수를 동시에 적용하거나, 열별로 다른 집계 함수를 지정할 수 있습니다.

**사용 사례**:
- 다중 통계 계산
- 열별 맞춤 집계
- 사용자 정의 집계
- 복잡한 데이터 요약
- 리포트 생성

```python
# 여러 집계 함수 동시 적용
print(grouped.agg(['mean', 'sum', 'count']))

# 열별로 다른 집계 함수
print(grouped.agg({'급여': 'mean', '이름': 'count'}))

# 사용자 정의 함수
print(grouped.agg(lambda x: x.max() - x.min()))
```

### 10.3 그룹별 연산

**설명**: 그룹화된 데이터에 대해 첫 번째, 마지막, 크기 등의 기본 연산을 수행합니다. 그룹의 특성을 파악하는 데 유용합니다.

**사용 사례**:
- 그룹의 첫/마지막 값 확인
- 그룹 크기 확인
- 그룹별 샘플 추출
- 그룹 통계
- 데이터 탐색

```python
# 그룹별 첫 번째 값
print(grouped.first())

# 그룹별 마지막 값
print(grouped.last())

# 그룹별 크기
print(grouped.size())

# 그룹별 개수 (결측치 제외)
print(grouped.count())
```

### 10.4 여러 열로 그룹화

**설명**: 여러 열을 기준으로 그룹화하여 계층적 그룹 분석을 수행합니다. 다차원 데이터 분석에 유용합니다.

**사용 사례**:
- 다중 기준 그룹 분석
- 계층적 데이터 분석
- 교차 분석
- 복잡한 그룹 통계
- 다차원 데이터 요약

```python
df = pd.DataFrame({
    '부서': ['개발', '개발', '디자인', '디자인'],
    '직급': ['주임', '대리', '주임', '대리'],
    '급여': [3000, 3500, 4000, 4500]
})

# 여러 열로 그룹화
grouped = df.groupby(['부서', '직급'])
print(grouped.mean())
```

### 10.5 transform과 apply

**설명**: 그룹별 연산을 수행하되, `transform`은 원본 크기를 유지하고, `apply`는 사용자 정의 함수를 적용할 수 있습니다.

**사용 사례**:
- 그룹별 정규화 (transform)
- 그룹별 평균/표준편차 추가
- 복잡한 그룹 연산 (apply)
- 사용자 정의 그룹 함수
- 데이터 변환

```python
# transform: 그룹별 연산 후 원본 크기 유지
df['부서평균급여'] = df.groupby('부서')['급여'].transform('mean')
print(df)

# apply: 그룹별 사용자 정의 함수 적용
def normalize(group):
    return (group - group.mean()) / group.std()

df['정규화급여'] = df.groupby('부서')['급여'].apply(normalize)
print(df)
```

---

## 11. 데이터 병합 및 조인

### 11.1 concat: 연결

**설명**: 여러 DataFrame을 행 또는 열 방향으로 연결합니다. 동일한 구조의 데이터를 합칠 때 사용합니다.

**사용 사례**:
- 여러 데이터셋 결합
- 월별/일별 데이터 합치기
- 여러 소스 데이터 통합
- 데이터 누적
- 배치 데이터 결합

```python
df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})

# 행 방향 연결
result = pd.concat([df1, df2], ignore_index=True)
print(result)

# 열 방향 연결
result = pd.concat([df1, df2], axis=1)
print(result)
```

### 11.2 merge: 병합

**설명**: 두 개 이상의 DataFrame을 공통 열(키)을 기준으로 병합합니다. SQL의 JOIN 연산과 동일합니다.

**사용 사례**:
- 여러 데이터 소스 결합 (고객 정보 + 주문 정보)
- 데이터베이스 조인 연산
- 참조 데이터 병합 (코드 테이블과 실제 데이터)
- 데이터 보강 (추가 정보 병합)
- 관계형 데이터 처리

```python
df1 = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희'],
    '부서': ['개발', '디자인', '개발']
})

df2 = pd.DataFrame({
    '이름': ['홍길동', '김철수', '박민수'],
    '급여': [3000, 4000, 5000]
})

# 내부 조인 (기본값)
result = pd.merge(df1, df2, on='이름')
print(result)

# 왼쪽 조인
result = pd.merge(df1, df2, on='이름', how='left')
print(result)

# 오른쪽 조인
result = pd.merge(df1, df2, on='이름', how='right')
print(result)

# 외부 조인
result = pd.merge(df1, df2, on='이름', how='outer')
print(result)

# 다른 열 이름으로 조인
df1 = pd.DataFrame({'이름': ['홍길동', '김철수'], '나이': [25, 30]})
df2 = pd.DataFrame({'name': ['홍길동', '김철수'], '급여': [3000, 4000]})
result = pd.merge(df1, df2, left_on='이름', right_on='name')
print(result)

# 여러 열로 조인
df1 = pd.DataFrame({
    '이름': ['홍길동', '김철수'],
    '부서': ['개발', '디자인'],
    '나이': [25, 30]
})
df2 = pd.DataFrame({
    '이름': ['홍길동', '김철수'],
    '부서': ['개발', '디자인'],
    '급여': [3000, 4000]
})
result = pd.merge(df1, df2, on=['이름', '부서'])
print(result)
```

#### 11.2.5 인덱스 기준 병합 (`left_index`, `right_index`)

**설명**: `merge` 함수에서 열(column) 대신 **인덱스(index)**를 병합 키로 사용할 때 지정하는 옵션입니다.

- `left_index=True`: 왼쪽 DataFrame의 인덱스를 키로 사용
- `right_index=True`: 오른쪽 DataFrame의 인덱스를 키로 사용
- `left_on` / `right_on`과 혼합하여 사용 가능 (예: 왼쪽은 열, 오른쪽은 인덱스)

**사용 사례**:
- 한쪽 DataFrame이 이미 인덱스로 키를 가지고 있을 때
- 멀티 인덱스(MultiIndex)를 활용하여 병합할 때
- `set_index()` 후 병합하는 과정을 줄이고 싶을 때

**예제**:

```python
# 왼쪽: 열 기준, 오른쪽: 인덱스 기준
df1 = pd.DataFrame({'도시': ['서울', '부산'], '값': [1, 2]})
df2 = pd.DataFrame({'인구': [1000, 350]}, index=['서울', '부산'])

# df1의 '도시' 열과 df2의 인덱스를 매칭
result = pd.merge(df1, df2, left_on='도시', right_index=True)
print(result)
#    도시  값    인구
# 0  서울  1  1000
# 1  부산  2   350
```

### 11.3 join: 인덱스 기반 조인

**설명**: 인덱스를 기준으로 두 DataFrame을 조인합니다. `merge`와 유사하지만 인덱스를 키로 사용합니다.

**사용 사례**:
- 인덱스가 키인 경우
- 시계열 데이터 병합
- 인덱스 기반 데이터 결합
- 간단한 조인 (인덱스 사용)
- 날짜/시간 인덱스 병합

```python
df1 = pd.DataFrame({'A': [1, 2, 3]}, index=['a', 'b', 'c'])
df2 = pd.DataFrame({'B': [4, 5, 6]}, index=['a', 'b', 'd'])

# 인덱스로 조인
result = df1.join(df2, how='inner')
print(result)
```

### 11.4 concat, merge, join 비교

**설명**: 세 가지 데이터 병합 방법의 차이점과 언제 사용해야 하는지 비교합니다.

#### 비교 표

| 특징 | concat | merge | join |
|------|--------|-------|------|
| **용도** | 데이터 연결 (추가) | 키 기반 병합 | 인덱스 기반 병합 |
| **기준** | 인덱스/위치 | 공통 열(키) | 인덱스 |
| **방향** | 행/열 방향 | 수평 병합 | 수평 병합 |
| **SQL 유사** | UNION | JOIN | JOIN (인덱스) |
| **사용 시나리오** | 동일 구조 데이터 합치기 | 관계형 데이터 병합 | 인덱스가 키인 경우 |

#### 상세 비교

**concat - 데이터 연결**
- **목적**: 동일한 구조의 데이터를 단순히 연결
- **기준**: 인덱스나 위치
- **방향**: 행 방향(axis=0) 또는 열 방향(axis=1)
- **사용 예**: 월별 데이터 합치기, 여러 파일 데이터 통합

```python
# 동일한 구조의 데이터 연결
df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})
result = pd.concat([df1, df2])  # 행 방향 연결
```

**merge - 키 기반 병합**
- **목적**: 공통 열(키)을 기준으로 데이터 병합
- **기준**: 공통 열 이름 또는 지정된 열
- **방향**: 수평 병합 (열 추가)
- **사용 예**: 고객 정보 + 주문 정보, 관계형 데이터 결합

```python
# 공통 열을 기준으로 병합
df1 = pd.DataFrame({'이름': ['홍길동', '김철수'], '부서': ['개발', '디자인']})
df2 = pd.DataFrame({'이름': ['홍길동', '김철수'], '급여': [3000, 4000]})
result = pd.merge(df1, df2, on='이름')  # '이름' 열 기준 병합
```

**join - 인덱스 기반 병합**
- **목적**: 인덱스를 기준으로 데이터 병합
- **기준**: 인덱스
- **방향**: 수평 병합 (열 추가)
- **사용 예**: 시계열 데이터 병합, 인덱스가 키인 경우

```python
# 인덱스를 기준으로 병합
df1 = pd.DataFrame({'A': [1, 2]}, index=['a', 'b'])
df2 = pd.DataFrame({'B': [3, 4]}, index=['a', 'b'])
result = df1.join(df2)  # 인덱스 기준 병합
```

#### 언제 무엇을 사용할까?

**concat 사용 시기**
- ✅ 동일한 구조의 데이터를 단순히 합칠 때
- ✅ 여러 파일에서 읽은 데이터를 하나로 합칠 때
- ✅ 월별/일별 데이터를 누적할 때
- ✅ 행이나 열을 추가할 때

**merge 사용 시기**
- ✅ 공통 열(키)을 기준으로 데이터를 병합할 때
- ✅ 관계형 데이터베이스의 JOIN과 같은 작업
- ✅ 다른 이름의 열을 키로 사용할 때
- ✅ 여러 열을 복합 키로 사용할 때
- ✅ 다양한 조인 타입(inner, left, right, outer)이 필요할 때

**join 사용 시기**
- ✅ 인덱스가 키 역할을 할 때
- ✅ 시계열 데이터를 병합할 때
- ✅ 인덱스 기반으로 간단하게 병합할 때
- ✅ merge보다 간단한 문법이 필요할 때

#### 실전 예제 비교

```python
# 예제 데이터
df1 = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희'],
    '부서': ['개발', '디자인', '개발']
})

df2 = pd.DataFrame({
    '이름': ['홍길동', '김철수', '박민수'],
    '급여': [3000, 4000, 5000]
})

df3 = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희'],
    '부서': ['개발', '디자인', '개발']
})

# 1. concat: 동일 구조 데이터 연결
result_concat = pd.concat([df1, df3], ignore_index=True)
# 결과: 6개 행 (df1의 3개 + df3의 3개)

# 2. merge: 공통 열 기준 병합
result_merge = pd.merge(df1, df2, on='이름', how='inner')
# 결과: 2개 행 (공통된 '홍길동', '김철수'만)

# 3. join: 인덱스 기준 병합
df1_indexed = df1.set_index('이름')
df2_indexed = df2.set_index('이름')
result_join = df1_indexed.join(df2_indexed, how='inner')
# 결과: 인덱스(이름) 기준으로 병합
```

#### 요약

- **concat**: 데이터를 단순히 연결 (추가)
- **merge**: 공통 열을 기준으로 병합 (JOIN)
- **join**: 인덱스를 기준으로 병합 (간단한 JOIN)

대부분의 경우 **merge**가 가장 유연하고 강력하며, **concat**은 동일 구조 데이터 연결에, **join**은 인덱스 기반 병합에 특화되어 있습니다.

---

## 12. 문자열 처리

### 12.1 기본 문자열 메서드

**설명**: 문자열 열에 대해 다양한 문자열 메서드를 적용할 수 있습니다. `.str` 접근자를 통해 벡터화된 문자열 연산을 수행합니다.

**사용 사례**:
- 대소문자 변환
- 공백 제거
- 문자열 길이 계산
- 문자열 정규화
- 텍스트 데이터 전처리

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희'],
    '이메일': ['hong@email.com', 'KIM@EMAIL.COM', 'lee@email.com']
})

# 대소문자 변환
df['이메일_소문자'] = df['이메일'].str.lower()
df['이메일_대문자'] = df['이메일'].str.upper()

# 문자열 길이
df['이름_길이'] = df['이름'].str.len()

# 공백 제거
df['이름_trim'] = df['이름'].str.strip()
```

### 12.2 문자열 검색 및 추출

**설명**: 문자열에서 패턴을 검색하거나 추출합니다. 정규표현식을 사용하여 복잡한 패턴도 처리할 수 있습니다.

**사용 사례**:
- 패턴 매칭
- 문자열 추출 (이메일 도메인 등)
- 문자열 치환
- 데이터 정제
- 텍스트 마이닝

```python
# 포함 여부
print(df[df['이메일'].str.contains('@')])

# 시작/끝 문자열
print(df[df['이메일'].str.startswith('hong')])
print(df[df['이메일'].str.endswith('.com')])

# 정규표현식 추출
df['도메인'] = df['이메일'].str.extract(r'@(.+)')
print(df)

# 정규표현식 치환
df['이메일_변경'] = df['이메일'].str.replace(r'@', '[at]')
print(df)
```

### 12.3 문자열 분할

**설명**: 문자열을 분할하여 여러 열로 나누거나 부분 문자열을 추출합니다. 구분자를 기준으로 분할할 수 있습니다.

**사용 사례**:
- 이름 분리 (성, 이름)
- 주소 분리 (시, 구, 동)
- 구분자로 분리된 데이터 처리
- 부분 문자열 추출
- 텍스트 파싱

```python
# 분할
df['이름_성'] = df['이름'].str[0]  # 첫 글자
df['이름_이름'] = df['이름'].str[1:]  # 나머지

# split 메서드
df[['이름_성', '이름_이름']] = df['이름'].str.split('', expand=True)
```

---

## 13. 시계열 데이터 처리

### 13.1 날짜/시간 생성

**설명**: 날짜와 시간 데이터를 생성하고 처리하는 기능입니다. 시계열 데이터 분석의 기초가 됩니다.

**사용 사례**:
- 시계열 데이터 인덱스 생성
- 날짜 범위 기반 데이터 필터링
- 시간별/일별/월별 집계
- 주식 가격, 센서 데이터 등 시계열 분석
- 리포트 생성 (기간별 데이터)

```python
# 날짜 범위 생성
dates = pd.date_range('2024-01-01', periods=10, freq='D')
print(dates)

# 다양한 주기
dates_d = pd.date_range('2024-01-01', periods=10, freq='D')  # 일
dates_w = pd.date_range('2024-01-01', periods=10, freq='W')  # 주
dates_m = pd.date_range('2024-01-01', periods=10, freq='M')  # 월

# 문자열을 날짜로 변환
df = pd.DataFrame({'날짜': ['2024-01-01', '2024-01-02', '2024-01-03']})
df['날짜'] = pd.to_datetime(df['날짜'])
print(df.dtypes)
```

### 13.2 날짜/시간 속성 추출

**설명**: 날짜/시간 데이터에서 년, 월, 일, 요일 등의 속성을 추출합니다. 시계열 분석의 기본 작업입니다.

**사용 사례**:
- 년/월/일별 분석
- 요일별 패턴 분석
- 계절성 분석
- 시간대별 분석
- 날짜 기반 필터링

```python
df = pd.DataFrame({
    '날짜': pd.date_range('2024-01-01', periods=5, freq='D'),
    '값': [10, 20, 30, 40, 50]
})

# 년, 월, 일 추출
df['년'] = df['날짜'].dt.year
df['월'] = df['날짜'].dt.month
df['일'] = df['날짜'].dt.day
df['요일'] = df['날짜'].dt.day_name()
df['요일번호'] = df['날짜'].dt.dayofweek

print(df)
```

### 13.3 시계열 인덱싱

**설명**: 날짜/시간을 인덱스로 사용하여 시계열 데이터를 인덱싱합니다. 날짜 범위로 슬라이싱할 수 있습니다.

**사용 사례**:
- 특정 날짜 데이터 추출
- 날짜 범위 선택
- 시계열 데이터 필터링
- 기간별 데이터 분석
- 시간 기반 데이터 접근

```python
# 날짜를 인덱스로 설정
df_indexed = df.set_index('날짜')

# 날짜로 인덱싱
print(df_indexed['2024-01-01'])
print(df_indexed['2024-01'])

# 날짜 범위
print(df_indexed['2024-01-01':'2024-01-03'])
```

### 13.4 리샘플링

**설명**: 시계열 데이터를 다른 주기로 재샘플링합니다. 일별 데이터를 주별, 월별로 집계하는 등 시간 단위를 변경할 수 있습니다.

**사용 사례**:
- 시간 단위 변경 (일→월, 분→시간)
- 주기별 집계
- 데이터 다운샘플링/업샘플링
- 시계열 데이터 요약
- 리포트 생성 (월별, 연도별)

```python
# 일별 데이터를 월별로 집계
df_monthly = df_indexed.resample('M').mean()
print(df_monthly)

# 다양한 주기
df_weekly = df_indexed.resample('W').sum()
df_yearly = df_indexed.resample('Y').sum()
```

---

## 14. 통계 함수

### 14.1 기본 통계

**설명**: DataFrame의 숫자형 열에 대해 기본 통계량을 계산합니다. 데이터의 분포와 특성을 파악하는 데 사용됩니다.

**사용 사례**:
- 데이터 요약 통계
- 데이터 분포 파악
- 이상치 탐지
- 데이터 품질 검사
- 탐색적 데이터 분석 (EDA)

```python
df = pd.DataFrame({
    'A': [1, 2, 3, 4, 5],
    'B': [10, 20, 30, 40, 50],
    'C': [100, 200, 300, 400, 500]
})

# 기본 통계
print(df.mean())    # 평균
print(df.median())  # 중앙값
print(df.std())     # 표준편차
print(df.var())     # 분산
print(df.min())     # 최솟값
print(df.max())     # 최댓값
print(df.sum())     # 합계
print(df.count())   # 개수
```

#### 각 통계 함수 설명

**mean() - 평균**
- **설명**: 모든 값의 산술 평균을 계산합니다.
- **계산식**: mean = (x₁ + x₂ + ... + xₙ) / n
- **예제**: [1, 2, 3, 4, 5]의 평균 = (1+2+3+4+5)/5 = 3.0

```python
# 예제
data = [1, 2, 3, 4, 5]
mean = sum(data) / len(data)  # 3.0
print(df['A'].mean())  # 3.0
```

**median() - 중앙값**
- **설명**: 데이터를 정렬했을 때 중앙에 위치한 값입니다. 이상치에 덜 민감합니다.
- **계산식**: 데이터를 정렬한 후 중앙값 선택
  - 홀수 개: (n+1)/2 번째 값
  - 짝수 개: n/2 번째와 (n/2)+1 번째 값의 평균
- **예제**: [1, 2, 3, 4, 5]의 중앙값 = 3 (정렬 후 중앙값)
- **예제**: [1, 2, 3, 4, 5, 6]의 중앙값 = (3+4)/2 = 3.5

```python
# 예제
data = [1, 2, 3, 4, 5]
sorted_data = sorted(data)
median = sorted_data[len(sorted_data) // 2]  # 3
print(df['A'].median())  # 3.0
```

**std() - 표준편차**
- **설명**: 데이터가 평균으로부터 얼마나 퍼져있는지를 나타내는 지표입니다.
- **계산식**: std = √(Σ(xᵢ - mean)² / (n-1))  (표본 표준편차, ddof=1)
- **예제**: [1, 2, 3, 4, 5]의 표준편차
  - 평균 = 3
  - 분산 = ((1-3)² + (2-3)² + (3-3)² + (4-3)² + (5-3)²) / 4 = 2.5
  - 표준편차 = √2.5 ≈ 1.58

```python
# 예제
data = [1, 2, 3, 4, 5]
mean = sum(data) / len(data)
variance = sum((x - mean) ** 2 for x in data) / (len(data) - 1)
std = variance ** 0.5  # 약 1.58
print(df['A'].std())  # 1.5811388300841898
```

**var() - 분산**
- **설명**: 데이터가 평균으로부터 얼마나 퍼져있는지를 나타내는 지표의 제곱입니다.
- **계산식**: var = Σ(xᵢ - mean)² / (n-1)  (표본 분산, ddof=1)
- **예제**: [1, 2, 3, 4, 5]의 분산
  - 평균 = 3
  - 분산 = ((1-3)² + (2-3)² + (3-3)² + (4-3)² + (5-3)²) / 4 = 2.5

```python
# 예제
data = [1, 2, 3, 4, 5]
mean = sum(data) / len(data)
variance = sum((x - mean) ** 2 for x in data) / (len(data) - 1)  # 2.5
print(df['A'].var())  # 2.5
```

**min() - 최솟값**
- **설명**: 데이터 중 가장 작은 값을 반환합니다.
- **계산식**: min = min(x₁, x₂, ..., xₙ)
- **예제**: [1, 2, 3, 4, 5]의 최솟값 = 1

```python
# 예제
data = [1, 2, 3, 4, 5]
minimum = min(data)  # 1
print(df['A'].min())  # 1
```

**max() - 최댓값**
- **설명**: 데이터 중 가장 큰 값을 반환합니다.
- **계산식**: max = max(x₁, x₂, ..., xₙ)
- **예제**: [1, 2, 3, 4, 5]의 최댓값 = 5

```python
# 예제
data = [1, 2, 3, 4, 5]
maximum = max(data)  # 5
print(df['A'].max())  # 5
```

**sum() - 합계**
- **설명**: 모든 값의 합을 계산합니다.
- **계산식**: sum = x₁ + x₂ + ... + xₙ
- **예제**: [1, 2, 3, 4, 5]의 합계 = 1+2+3+4+5 = 15

```python
# 예제
data = [1, 2, 3, 4, 5]
total = sum(data)  # 15
print(df['A'].sum())  # 15
```

**count() - 개수**
- **설명**: 결측치(NaN)를 제외한 데이터의 개수를 반환합니다.
- **계산식**: count = 결측치가 아닌 값의 개수
- **예제**: [1, 2, NaN, 4, 5]의 개수 = 4 (NaN 제외)

```python
# 예제
data = [1, 2, np.nan, 4, 5]
count = len([x for x in data if not pd.isna(x)])  # 4
print(df['A'].count())  # 5 (결측치 없음)
```

### 14.2 상관관계와 공분산

**설명**: 열 간의 상관관계와 공분산을 계산합니다. 변수 간의 관계를 파악하는 데 사용됩니다.

**사용 사례**:
- 변수 간 관계 분석
- 다중공선성 검사
- 특성 선택 (상관관계 높은 변수 제거)
- 데이터 탐색
- 통계 분석

```python
# 상관관계
print(df.corr())

# 공분산
print(df.cov())
```

### 14.3 백분위수

**설명**: 데이터의 백분위수를 계산합니다. 데이터의 분포를 이해하고 이상치를 탐지하는 데 유용합니다.

**사용 사례**:
- 데이터 분포 분석
- 이상치 탐지 (IQR 방법)
- 박스 플롯 생성
- 통계적 요약
- 데이터 품질 검사

```python
# 백분위수
print(df.quantile(0.25))  # 25%
print(df.quantile(0.5))   # 50% (중앙값)
print(df.quantile(0.75))  # 75%

# 여러 백분위수
print(df.quantile([0.25, 0.5, 0.75]))
```

### 14.4 누적 통계

**설명**: 데이터를 순차적으로 누적하여 계산합니다. 각 위치에서 이전까지의 누적값을 계산합니다.

**사용 사례**:
- 누적 합/곱 계산
- 누적 수익률 계산
- 이동 평균 계산
- 시간별 누적 데이터
- 재무 분석

```python
# 누적 합
print(df.cumsum())

# 누적 곱
print(df.cumprod())

# 누적 최댓값/최솟값
print(df.cummax())
print(df.cummin())
```

---

## 15. 데이터 시각화

### 15.1 기본 플롯 (plot 메서드)

**설명**: Pandas는 Matplotlib을 기반으로 한 간편한 시각화 기능을 제공합니다. `plot()` 메서드를 사용하여 DataFrame이나 Series의 데이터를 빠르게 시각화할 수 있습니다.

**주요 파라미터**:
- `kind`: 그래프 종류 ('line', 'bar', 'barh', 'hist', 'box', 'kde', 'density', 'area', 'pie', 'scatter', 'hexbin')
- `x`, `y`: x축과 y축에 사용할 컬럼명
- `figsize`: 그래프 크기 (튜플, 예: `(10, 6)`)
- `title`: 그래프 제목
- `grid`: 격자 표시 여부 (True/False)
- `legend`: 범례 표시 여부 (True/False)
- `style`: 선 스타일 (리스트 또는 딕셔너리)
- `color`: 색상
- `alpha`: 투명도 (0~1)
- `subplots`: 각 컬럼을 별도의 서브플롯으로 그릴지 여부

**사용 사례**:
- 데이터 탐색 (EDA)
- 트렌드 및 패턴 확인
- 데이터 분포 확인
- 변수 간 관계 분석

```python
import matplotlib.pyplot as plt

# 샘플 데이터 생성
df = pd.DataFrame({
    '월': [1, 2, 3, 4, 5, 6],
    '매출': [100, 120, 140, 130, 150, 160],
    '이익': [30, 40, 35, 30, 45, 50]
})

# 기본 선 그래프 (x축: 인덱스, y축: 모든 수치형 컬럼)
df.plot()
plt.show()

# x, y 축 지정 및 스타일 설정
df.plot(x='월', y='매출', kind='line', title='월별 매출', 
        figsize=(8, 5), grid=True, marker='o')
plt.show()
```

### 15.2 주요 플롯 타입 상세

#### 15.2.1 선 그래프 (Line Plot)
- **기본값**: `kind='line'`
- **용도**: 시계열 데이터나 연속적인 데이터의 변화 추이를 볼 때 사용합니다.

```python
# 다중 컬럼 선 그래프
df.plot(x='월', y=['매출', '이익'], marker='o')
plt.title('매출 및 이익 추이')
plt.show()
```

#### 15.2.2 막대 그래프 (Bar Plot)
- **옵션**: `kind='bar'` (수직), `kind='barh'` (수평)
- **용도**: 범주형 데이터의 크기를 비교할 때 사용합니다.

```python
# 수직 막대 그래프
df.plot(x='월', y='매출', kind='bar', rot=0)
plt.title('월별 매출 (Bar)')
plt.show()

# 수평 막대 그래프
df.plot(x='월', y='매출', kind='barh', color='skyblue')
plt.title('월별 매출 (Horizontal Bar)')
plt.show()

# 누적 막대 그래프
df.plot(x='월', kind='bar', stacked=True)
plt.title('누적 막대 그래프')
plt.show()
```

#### 15.2.3 산점도 (Scatter Plot)
- **옵션**: `kind='scatter'`
- **용도**: 두 변수 간의 상관관계를 파악할 때 사용합니다. 점의 크기(`s`)와 색상(`c`)을 통해 추가 정보를 표현할 수 있습니다.

```python
# 기본 산점도
df.plot(kind='scatter', x='매출', y='이익', s=50, c='red')
plt.title('매출과 이익의 관계')
plt.show()

# 점 크기와 색상 매핑
df.plot(kind='scatter', x='매출', y='이익', 
        s=df['매출']/2, c='월', colormap='viridis')
plt.title('매출/이익 관계 (크기: 매출, 색상: 월)')
plt.show()
```

#### 15.2.4 히스토그램 (Histogram)
- **옵션**: `kind='hist'`
- **용도**: 데이터의 분포를 확인할 때 사용합니다. `bins`로 구간 수를 조절합니다.

```python
# 히스토그램
df['매출'].plot(kind='hist', bins=5, alpha=0.7)
plt.title('매출 분포')
plt.show()

# 여러 컬럼 히스토그램 (투명도 조절로 겹쳐서 표현)
df[['매출', '이익']].plot(kind='hist', alpha=0.5, bins=10)
plt.show()
```

#### 15.2.5 박스 플롯 (Box Plot)
- **옵션**: `kind='box'`
- **용도**: 데이터의 통계적 분포(중앙값, 사분위수)와 이상치를 확인할 때 사용합니다.

```python
# 박스 플롯
df[['매출', '이익']].plot(kind='box')
plt.title('매출 및 이익 분포')
plt.show()

# 그룹별 박스 플롯 (boxplot 메서드 사용)
# df.boxplot(column='매출', by='월')
```

#### 15.2.6 파이 차트 (Pie Chart)
- **옵션**: `kind='pie'`
- **용도**: 전체에 대한 각 부분의 비율을 표현할 때 사용합니다.

```python
# 파이 차트
df.set_index('월')['매출'].plot(kind='pie', autopct='%1.1f%%', figsize=(6, 6))
plt.title('월별 매출 비율')
plt.ylabel('')  # y축 라벨 제거
plt.show()
```

### 15.3 고급 시각화 기능

#### 15.3.1 서브플롯 (Subplots)
- `subplots=True` 옵션을 사용하여 각 컬럼을 별도의 그래프로 그릴 수 있습니다.
- `layout` 옵션으로 배치(행, 열)를 지정할 수 있습니다.

```python
# 서브플롯 생성
df.plot(subplots=True, layout=(1, 3), figsize=(15, 4), sharey=False)
plt.suptitle('서브플롯 예제')
plt.show()
```

#### 15.3.2 이중 축 (Secondary Y-axis)
- `secondary_y` 옵션을 사용하여 단위가 다른 두 데이터를 하나의 그래프에 표현할 수 있습니다.

```python
# 이중 축 그래프
ax = df.plot(x='월', y='매출', kind='bar', legend=False)
df.plot(x='월', y='이익', kind='line', secondary_y=True, ax=ax, color='red', marker='o')
plt.title('매출(막대) 및 이익(선) 이중 축')
plt.show()
```

#### 15.3.3 Matplotlib 연동 커스터마이징
- Pandas의 `plot()` 메서드는 Matplotlib의 `Axes` 객체를 반환합니다.
- 이를 변수로 받아 Matplotlib의 다양한 함수로 그래프를 상세하게 꾸밀 수 있습니다.

```python
# Axes 객체 활용
ax = df.plot(kind='line', marker='o')

# Matplotlib 함수로 커스터마이징
ax.set_title("커스텀 타이틀", fontsize=15, color='blue')
ax.set_xlabel("인덱스", fontsize=12)
ax.set_ylabel("값", fontsize=12)
ax.legend(["Sales", "Profit"], loc='upper left')
ax.grid(True, linestyle='--', alpha=0.6)

plt.show()
```

---

## 16. 실전 예제

### 16.1 데이터 정제 예제

```python
# 샘플 데이터
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수', '최지영'],
    '나이': [25, None, 28, 35, 22],
    '급여': [3000, 4000, None, 5000, 2500],
    '부서': ['개발', '개발', '디자인', '기획', '개발']
})

# 1. 결측치 확인
print("결측치 개수:")
print(df.isna().sum())

# 2. 나이 결측치를 평균으로 채우기
df['나이'] = df['나이'].fillna(df['나이'].mean())

# 3. 급여 결측치를 부서별 평균으로 채우기
df['급여'] = df.groupby('부서')['급여'].transform(
    lambda x: x.fillna(x.mean())
)

# 4. 결과 확인
print("\n정제 후 데이터:")
print(df)
```

### 16.2 그룹별 분석 예제

```python
# 부서별 통계
dept_stats = df.groupby('부서').agg({
    '나이': ['mean', 'min', 'max'],
    '급여': ['mean', 'sum', 'count']
})

print("부서별 통계:")
print(dept_stats)

# 부서별 평균 급여가 높은 순으로 정렬
dept_avg_salary = df.groupby('부서')['급여'].mean().sort_values(ascending=False)
print("\n부서별 평균 급여:")
print(dept_avg_salary)
```

### 16.3 데이터 병합 예제

```python
# 직원 정보
employees = pd.DataFrame({
    '직원ID': [1, 2, 3, 4],
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '부서ID': [10, 10, 20, 30]
})

# 부서 정보
departments = pd.DataFrame({
    '부서ID': [10, 20, 30],
    '부서명': ['개발', '디자인', '기획']
})

# 병합
result = pd.merge(employees, departments, on='부서ID', how='left')
print(result)
```

### 16.4 시계열 분석 예제

```python
# 일별 매출 데이터
dates = pd.date_range('2024-01-01', periods=30, freq='D')
sales = pd.DataFrame({
    '날짜': dates,
    '매출': np.random.randint(1000, 5000, 30)
})

sales = sales.set_index('날짜')

# 주별 집계
weekly_sales = sales.resample('W').sum()
print("주별 매출:")
print(weekly_sales)

# 월별 집계
monthly_sales = sales.resample('M').sum()
print("\n월별 매출:")
print(monthly_sales)

# 이동 평균
sales['7일이동평균'] = sales['매출'].rolling(window=7).mean()
print("\n7일 이동 평균:")
print(sales)
```

### 16.5 피벗 테이블 예제

```python
df = pd.DataFrame({
    '부서': ['개발', '개발', '디자인', '디자인', '기획', '기획'],
    '직급': ['주임', '대리', '주임', '대리', '주임', '대리'],
    '급여': [3000, 3500, 4000, 4500, 5000, 5500]
})

# 피벗 테이블
pivot = pd.pivot_table(df, values='급여', index='부서', columns='직급', aggfunc='mean')
print("피벗 테이블:")
print(pivot)
```

---

## 17. 요약

### 17.1 핵심 개념

1. **Series**: 1차원 레이블이 있는 배열
2. **DataFrame**: 2차원 레이블이 있는 테이블 구조
3. **인덱싱**: `loc` (라벨), `iloc` (위치) 사용
4. **필터링**: 불리언 인덱싱, `query()` 메서드
5. **그룹화**: `groupby()`로 그룹별 연산
6. **병합**: `merge()`, `concat()`, `join()` 사용
7. **결측치**: `isna()`, `fillna()`, `dropna()` 처리
8. **시계열**: `pd.to_datetime()`, `resample()` 사용
9. **문자열**: `.str` 접근자로 문자열 메서드 사용
10. **통계**: `mean()`, `sum()`, `std()`, `corr()` 등

### 17.2 주요 메서드 요약

#### 데이터 읽기/쓰기
- `pd.read_csv()`, `pd.read_excel()`, `pd.read_json()`
- `df.to_csv()`, `df.to_excel()`, `df.to_json()`

#### 데이터 선택
- `df.loc[]`: 라벨 기반 인덱싱
- `df.iloc[]`: 위치 기반 인덱싱
- `df[조건]`: 불리언 인덱싱

#### 데이터 변형
- `df.drop()`: 행/열 삭제
- `df.rename()`: 이름 변경
- `df.set_index()`: 인덱스 설정
- `df.reset_index()`: 인덱스 리셋

#### 데이터 집계
- `df.groupby()`: 그룹화
- `df.agg()`: 집계 함수
- `df.pivot_table()`: 피벗 테이블

#### 결측치 처리
- `df.isna()`: 결측치 확인
- `df.fillna()`: 결측치 채우기
- `df.dropna()`: 결측치 제거

### 17.3 성능 팁

- **벡터화 연산**: 반복문 대신 벡터화된 연산 사용
- **적절한 데이터 타입**: 메모리 사용량 최적화
- **인덱스 활용**: 자주 사용하는 열을 인덱스로 설정
- **청크 읽기**: 대용량 파일은 `chunksize` 파라미터 사용

이 문서에서는 Pandas의 핵심적인 기능들을 다루었습니다. 데이터 분석을 위한 더 깊이 있는 내용(고급 집계, 피벗 테이블, 실전 예제 등)은 다음 문서를 참조하세요:

> [!TIP]
> **심화 학습**: [02-1. Pandas 심화: 데이터 처리 및 분석](02_1.%20python_pandas_advanced.md)

### 17.4 주의사항

Pandas를 사용할 때 자주 발생하는 실수와 주의해야 할 사항들을 상세히 설명합니다.

#### 17.4.1 인덱싱: `loc`와 `iloc`의 차이

**문제 상황**
- `loc`와 `iloc`를 혼동하여 예상치 못한 결과 발생
- 슬라이싱 시 끝점 포함 여부 차이로 인한 오류

**상세 설명**

**`loc` - 라벨 기반 인덱싱**
- 인덱스 이름(라벨)을 사용하여 선택
- 슬라이싱 시 **끝점 포함** (inclusive)
- 불리언 인덱싱 지원

```python
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희', '박민수'],
    '나이': [25, 30, 28, 35]
}, index=[0, 1, 2, 3])

# loc: 끝점 포함
print(df.loc[0:2])  # 인덱스 0, 1, 2 행 모두 포함 (3개 행)

# 불리언 인덱싱
print(df.loc[df['나이'] > 25])  # 조건에 맞는 행 선택
```

**`iloc` - 위치 기반 인덱싱**
- 정수 위치(0부터 시작)를 사용하여 선택
- 슬라이싱 시 **끝점 미포함** (exclusive, Python 리스트와 동일)
- 불리언 인덱싱 직접 지원 안 함

```python
# iloc: 끝점 미포함
print(df.iloc[0:2])  # 위치 0, 1 행만 (2개 행)

# 음수 인덱스 사용 가능
print(df.iloc[-1])   # 마지막 행
```

**실전 예제와 주의사항**

```python
# ⚠️ 주의: 인덱스가 정수일 때 혼동하기 쉬움
df = pd.DataFrame({'A': [1, 2, 3, 4]}, index=[0, 1, 2, 3])

# 같은 인덱스 값이지만 다른 결과
df.loc[0:2]   # 인덱스 0, 1, 2 (3개 행) - 라벨로 취급
df.iloc[0:2]  # 위치 0, 1 (2개 행) - 위치로 취급

# 인덱스가 문자열인 경우
df_str = pd.DataFrame({'A': [1, 2, 3]}, index=['a', 'b', 'c'])
df_str.loc['a':'c']   # 'a', 'b', 'c' 모두 포함
df_str.iloc[0:2]      # 위치 0, 1만 (2개 행)
```

**권장 사항**
- 행 선택 시 항상 `loc` 또는 `iloc` 명시적으로 사용
- 기본 인덱싱 `df[0:2]`는 피하기 (모호함)
- 슬라이싱 끝점 차이 항상 주의

#### 17.4.2 결측치: `None`과 `NaN`의 차이

**문제 상황**
- `None`과 `NaN`을 같은 것으로 착각
- 결측치 검사 시 예상치 못한 결과
- 연산 시 오류 발생

**상세 설명**

**`None` (Python 객체)**
- Python의 `None` 객체
- 객체 타입 (object dtype)
- 비교 시 `is None` 또는 `== None` 사용

**`NaN` (Not a Number)**
- NumPy의 부동소수점 타입
- float64 dtype
- 비교 시 `np.isnan()` 또는 `pd.isna()` 사용
- **중요**: `NaN == NaN`은 항상 `False`!

```python
import numpy as np

# None 예제
df = pd.DataFrame({'A': [1, None, 3]})
print(df['A'].dtype)  # object
print(df['A'].isna())  # [False, True, False]

# NaN 예제
df = pd.DataFrame({'A': [1, np.nan, 3]})
print(df['A'].dtype)  # float64
print(df['A'].isna())  # [False, True, False]

# ⚠️ 주의: NaN 비교
print(np.nan == np.nan)  # False (항상 False!)
print(np.isnan(np.nan))  # True (올바른 방법)
print(pd.isna(np.nan))   # True (Pandas 권장)
```

**실전 예제**

```python
# 결측치 확인
df = pd.DataFrame({
    'A': [1, None, 3, np.nan],
    'B': [1, 2, None, 4]
})

# 올바른 결측치 확인 방법
print(df.isna())        # 모든 결측치 확인 (None, NaN 모두)
print(df.isnull())      # isna()와 동일
print(df.notna())       # 결측치가 아닌 값

# ⚠️ 잘못된 방법
# print(df == None)     # None만 찾고 NaN은 못 찾음
# print(df == np.nan)   # 항상 False (NaN 비교 불가)

# 결측치 개수
print(df.isna().sum())  # 각 열별 결측치 개수
```

**타입별 동작 차이**

```python
# 정수 열에 None 삽입 → float64로 변환 (NaN으로 저장)
df = pd.DataFrame({'A': [1, 2, 3]})
df.loc[1, 'A'] = None
print(df['A'].dtype)  # float64 (정수는 NaN을 표현할 수 없음)
print(df['A'].iloc[1])  # NaN

# 문자열 열에 None 삽입 → object dtype 유지
df = pd.DataFrame({'A': ['a', 'b', 'c']})
df.loc[1, 'A'] = None
print(df['A'].dtype)  # object
print(df['A'].iloc[1])  # None
```

**권장 사항**
- 결측치 확인: 항상 `isna()` 또는 `isnull()` 사용
- 결측치 비교: `==` 사용 금지, `isna()` 사용
- 타입 변환 주의: 정수 열에 None 삽입 시 float64로 변환됨

#### 17.4.3 복사 vs 뷰 (Copy vs View)

**문제 상황**
- 뷰를 수정했는데 원본도 변경됨
- 복사본이 필요한데 뷰를 사용하여 예상치 못한 결과
- SettingWithCopyWarning 경고 발생

**상세 설명**

**뷰 (View)**
- 원본 데이터를 참조하는 객체
- 뷰를 수정하면 원본도 변경됨
- 메모리 효율적

**복사본 (Copy)**
- 원본 데이터의 독립적인 복사본
- 복사본을 수정해도 원본은 변경 안 됨
- 메모리 사용량 증가

**뷰가 생성되는 경우**

```python
df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})

# 슬라이싱은 뷰를 반환할 수 있음
view = df[0:2]  # 뷰일 수 있음 (보장되지 않음)

# 열 선택은 뷰
view_col = df['A']  # 뷰

# ⚠️ 주의: 뷰 수정 시 원본도 변경될 수 있음
view_col.iloc[0] = 999
print(df)  # 원본도 변경됨!
```

**복사본 생성**

```python
# 명시적 복사
df_copy = df.copy()  # 깊은 복사 (deep copy)
df_copy = df.copy(deep=False)  # 얕은 복사 (shallow copy)

# 복사본 수정은 원본에 영향 없음
df_copy['A'].iloc[0] = 999
print(df)  # 원본은 변경 안 됨
```

**SettingWithCopyWarning**

```python
# ⚠️ 경고 발생하는 코드
df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
df[df['A'] > 1]['B'] = 999  # SettingWithCopyWarning!

# 올바른 방법 1: loc 사용
df.loc[df['A'] > 1, 'B'] = 999

# 올바른 방법 2: 명시적 복사 후 수정
df_filtered = df[df['A'] > 1].copy()
df_filtered['B'] = 999
```

**실전 예제**

```python
# 문제 상황
df = pd.DataFrame({
    '이름': ['홍길동', '김철수', '이영희'],
    '나이': [25, 30, 28],
    '급여': [3000, 4000, 3500]
})

# ⚠️ 잘못된 방법: 뷰 수정
young = df[df['나이'] < 30]  # 뷰일 수 있음
young['급여'] = young['급여'] * 1.1  # 경고 발생, 원본도 변경될 수 있음

# ✅ 올바른 방법 1: loc 사용
df.loc[df['나이'] < 30, '급여'] = df.loc[df['나이'] < 30, '급여'] * 1.1

# ✅ 올바른 방법 2: 복사본 사용
young = df[df['나이'] < 30].copy()
young['급여'] = young['급여'] * 1.1
# 원본 df는 변경 안 됨
```

**체인 인덱싱 주의**

```python
# ⚠️ 체인 인덱싱 (Chained Indexing) - 피해야 함
df[df['A'] > 1]['B'] = 999  # 경고 발생

# ✅ 단일 loc 사용
df.loc[df['A'] > 1, 'B'] = 999  # 권장
```

**권장 사항**
- 원본 보존이 필요하면 `copy()` 명시적 사용
- 값 수정 시 `loc` 또는 `iloc` 사용 (체인 인덱싱 피하기)
- SettingWithCopyWarning 발생 시 코드 수정
- 뷰/복사본 동작은 보장되지 않으므로 명시적 복사 권장

#### 17.4.4 데이터 타입 (Data Types)

**문제 상황**
- 문자열이 숫자처럼 보여서 연산 시 오류
- 정수와 실수 혼동
- 타입 변환 실수

**상세 설명**

**주요 데이터 타입**

```python
# 정수 타입
int64    # 64비트 정수
int32    # 32비트 정수

# 실수 타입
float64  # 64비트 부동소수점
float32  # 32비트 부동소수점

# 객체 타입
object   # 문자열, 혼합 타입

# 불리언 타입
bool     # True/False

# 날짜/시간 타입
datetime64  # 날짜와 시간
```

**타입 확인**

```python
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [1.1, 2.2, 3.3],
    'C': ['a', 'b', 'c'],
    'D': [True, False, True]
})

print(df.dtypes)
# A      int64
# B    float64
# C     object
# D       bool
```

**타입 변환 문제**

```python
# ⚠️ 문제: 문자열이 숫자처럼 보임
df = pd.DataFrame({'A': ['1', '2', '3']})
print(df['A'].dtype)  # object (문자열)

# 연산 시 오류 또는 예상치 못한 결과
# print(df['A'] + 1)  # 문자열 연결: '11', '21', '31'

# ✅ 해결: 타입 변환
df['A'] = df['A'].astype(int)
print(df['A'].dtype)  # int64
print(df['A'] + 1)    # [2, 3, 4]

# 또는 pd.to_numeric() 사용
df['A'] = pd.to_numeric(df['A'])
```

**타입 변환 메서드**

```python
# astype(): 명시적 타입 변환
df['A'] = df['A'].astype(int)
df['A'] = df['A'].astype(float)
df['A'] = df['A'].astype(str)

# pd.to_numeric(): 숫자로 변환 (더 안전)
df['A'] = pd.to_numeric(df['A'], errors='coerce')  # 변환 실패 시 NaN

# pd.to_datetime(): 날짜로 변환
df['날짜'] = pd.to_datetime(df['날짜'])

# pd.to_timedelta(): 시간 간격으로 변환
df['간격'] = pd.to_timedelta(df['간격'])
```

**실전 예제**

```python
# 문제 상황: CSV에서 읽은 숫자가 문자열
df = pd.read_csv('data.csv')
print(df['가격'].dtype)  # object (문자열)

# 연산 불가
# print(df['가격'].sum())  # 오류 또는 잘못된 결과

# 해결 방법
df['가격'] = pd.to_numeric(df['가격'], errors='coerce')
print(df['가격'].dtype)  # float64
print(df['가격'].sum())  # 정상 작동

# 혼합 타입 문제
df = pd.DataFrame({'A': [1, '2', 3, '4']})
print(df['A'].dtype)  # object (혼합 타입)

# 숫자만 추출
df['A'] = pd.to_numeric(df['A'], errors='coerce')
print(df['A'])  # [1.0, 2.0, 3.0, 4.0]
```

**타입별 연산 주의사항**

```python
# 정수와 실수 연산
df = pd.DataFrame({'A': [1, 2, 3], 'B': [1.5, 2.5, 3.5]})
result = df['A'] + df['B']
print(result.dtype)  # float64 (결과는 실수)

# 문자열 연산
df = pd.DataFrame({'A': ['1', '2', '3']})
result = df['A'] + '0'
print(result)  # ['10', '20', '30'] (문자열 연결)

# 불리언 연산
df = pd.DataFrame({'A': [True, False, True]})
result = df['A'] & True
print(result)  # [True, False, True]
```

**권장 사항**
- 데이터 로드 후 `dtypes` 확인
- 연산 전 타입 확인 및 필요시 변환
- `pd.to_numeric()` 사용 시 `errors='coerce'` 옵션 고려
- 혼합 타입 열은 주의 깊게 처리

#### 17.4.5 기타 주의사항

**인덱스 중복**

```python
# 중복 인덱스가 있으면 예상치 못한 결과 발생 가능
df = pd.DataFrame({'A': [1, 2, 3]}, index=[0, 0, 1])
print(df.loc[0])  # 2개 행 반환 (중복 인덱스)

# 중복 확인
print(df.index.is_unique)  # False

# 중복 제거
df = df.reset_index(drop=True)  # 새 인덱스 생성
```

**메모리 사용량**

```python
# 대용량 데이터 처리 시 메모리 주의
df = pd.DataFrame({'A': range(1000000)})
print(df.memory_usage(deep=True))  # 메모리 사용량 확인

# 타입 최적화
df['A'] = df['A'].astype('int32')  # int64 → int32 (메모리 절약)
```

**인플레이스 연산**

```python
# inplace=True 사용 시 주의
df.dropna(inplace=True)  # 원본 수정, 반환값 None
# df = df.dropna()  # 새 객체 반환 (더 안전)
```

**정렬 후 인덱스**

```python
# 정렬 후 인덱스가 섞임
df = pd.DataFrame({'A': [3, 1, 2]})
df_sorted = df.sort_values('A')
print(df_sorted.index)  # [1, 2, 0] (원본 인덱스 유지)

# 인덱스 리셋
df_sorted = df.sort_values('A').reset_index(drop=True)
print(df_sorted.index)  # [0, 1, 2] (새 인덱스)
```

### 17.5 다음 단계

- **NumPy**: Pandas의 기반이 되는 라이브러리
- **Matplotlib/Seaborn**: 데이터 시각화
- **Scikit-learn**: 머신러닝 (Pandas DataFrame 활용)
- **Jupyter Notebook**: 대화형 데이터 분석 환경

---

**참고 자료**:
- [Pandas 공식 문서](https://pandas.pydata.org/docs/)
- [Pandas 튜토리얼](https://pandas.pydata.org/docs/user_guide/10min.html)
- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)

